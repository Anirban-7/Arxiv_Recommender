{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/FarberE/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/FarberE/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/FarberE/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>updated</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/2305.11154v1</td>\n",
       "      <td>2023.42</td>\n",
       "      <td>2023.42</td>\n",
       "      <td>non linear operator valued elliptic flows with...</td>\n",
       "      <td>differential equations on spaces of operators ...</td>\n",
       "      <td>ph</td>\n",
       "      <td>['mp']</td>\n",
       "      <td>['jean bernard bru', 'nathan metraud']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/2305.11103v1</td>\n",
       "      <td>2023.42</td>\n",
       "      <td>2023.42</td>\n",
       "      <td>blockwise inversion and algorithms for inverti...</td>\n",
       "      <td>using the blockwise matrix inversion inversion...</td>\n",
       "      <td>na</td>\n",
       "      <td>['na', 'na', 'mp']</td>\n",
       "      <td>['r thiru senthil']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/2305.11054v1</td>\n",
       "      <td>2023.42</td>\n",
       "      <td>2023.42</td>\n",
       "      <td>ising systems measures on the sphere and zonoids</td>\n",
       "      <td>we give an interpretation of a class of discre...</td>\n",
       "      <td>ap</td>\n",
       "      <td>['ap', 'mp', 'oc']</td>\n",
       "      <td>['andrea braides', 'antonin chambolle']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/2210.09458v2</td>\n",
       "      <td>2023.42</td>\n",
       "      <td>2022.83</td>\n",
       "      <td>mobility edge for levy matrices</td>\n",
       "      <td>levy matrices are symmetric random matrices wh...</td>\n",
       "      <td>pr</td>\n",
       "      <td>['pr', 'mp']</td>\n",
       "      <td>['amol aggarwal', 'charles bordenave', 'patric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/2205.08765v2</td>\n",
       "      <td>2023.42</td>\n",
       "      <td>2022.42</td>\n",
       "      <td>necessary and sufficient conditions for one di...</td>\n",
       "      <td>this paper deals with necessary and sufficient...</td>\n",
       "      <td>ca</td>\n",
       "      <td>['ca', 'ft', 'mp']</td>\n",
       "      <td>['pavol quittner']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            entry_id  updated  published  \\\n",
       "0  http://arxiv.org/abs/2305.11154v1  2023.42    2023.42   \n",
       "1  http://arxiv.org/abs/2305.11103v1  2023.42    2023.42   \n",
       "2  http://arxiv.org/abs/2305.11054v1  2023.42    2023.42   \n",
       "3  http://arxiv.org/abs/2210.09458v2  2023.42    2022.83   \n",
       "4  http://arxiv.org/abs/2205.08765v2  2023.42    2022.42   \n",
       "\n",
       "                                               title  \\\n",
       "0  non linear operator valued elliptic flows with...   \n",
       "1  blockwise inversion and algorithms for inverti...   \n",
       "2   ising systems measures on the sphere and zonoids   \n",
       "3                    mobility edge for levy matrices   \n",
       "4  necessary and sufficient conditions for one di...   \n",
       "\n",
       "                                             summary primary_category  \\\n",
       "0  differential equations on spaces of operators ...               ph   \n",
       "1  using the blockwise matrix inversion inversion...               na   \n",
       "2  we give an interpretation of a class of discre...               ap   \n",
       "3  levy matrices are symmetric random matrices wh...               pr   \n",
       "4  this paper deals with necessary and sufficient...               ca   \n",
       "\n",
       "           categories                                            authors  \n",
       "0              ['mp']             ['jean bernard bru', 'nathan metraud']  \n",
       "1  ['na', 'na', 'mp']                                ['r thiru senthil']  \n",
       "2  ['ap', 'mp', 'oc']            ['andrea braides', 'antonin chambolle']  \n",
       "3        ['pr', 'mp']  ['amol aggarwal', 'charles bordenave', 'patric...  \n",
       "4  ['ca', 'ft', 'mp']                                 ['pavol quittner']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/df_experiment', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>updated</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>http://arxiv.org/abs/2303.02294v1</td>\n",
       "      <td>2023.25</td>\n",
       "      <td>2023.25</td>\n",
       "      <td>reverse isoperimetric problems under curvature...</td>\n",
       "      <td>in this paper we solve several reverse isoperi...</td>\n",
       "      <td>mg</td>\n",
       "      <td>['mg', 'dg']</td>\n",
       "      <td>['kostiantyn drach', 'kateryna tatarko']</td>\n",
       "      <td>[in, this, paper, we, solve, several, reverse,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              entry_id  updated  published  \\\n",
       "902  http://arxiv.org/abs/2303.02294v1  2023.25    2023.25   \n",
       "\n",
       "                                                 title  \\\n",
       "902  reverse isoperimetric problems under curvature...   \n",
       "\n",
       "                                               summary primary_category  \\\n",
       "902  in this paper we solve several reverse isoperi...               mg   \n",
       "\n",
       "       categories                                   authors  \\\n",
       "902  ['mg', 'dg']  ['kostiantyn drach', 'kateryna tatarko']   \n",
       "\n",
       "                                                tokens  \n",
       "902  [in, this, paper, we, solve, several, reverse,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column with tokens\n",
    "df['tokens'] = df['summary'].apply(nltk.word_tokenize)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [differential, equations, on, spaces, of, oper...\n",
       "1    [using, the, blockwise, matrix, inversion, inv...\n",
       "2    [we, give, an, interpretation, of, a, class, o...\n",
       "3    [levy, matrices, are, symmetric, random, matri...\n",
       "4    [this, paper, deals, with, necessary, and, suf...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_strip(lst):\n",
    "    return [word for word in lst if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_strip(df['tokens'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['tokens'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>strip_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[differential, equations, on, spaces, of, oper...</td>\n",
       "      <td>[differential, equations, spaces, operators, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[using, the, blockwise, matrix, inversion, inv...</td>\n",
       "      <td>[using, blockwise, matrix, inversion, inversio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[we, give, an, interpretation, of, a, class, o...</td>\n",
       "      <td>[give, interpretation, class, discrete, contin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[levy, matrices, are, symmetric, random, matri...</td>\n",
       "      <td>[levy, matrices, symmetric, random, matrices, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[this, paper, deals, with, necessary, and, suf...</td>\n",
       "      <td>[paper, deals, necessary, sufficient, conditio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [differential, equations, on, spaces, of, oper...   \n",
       "1  [using, the, blockwise, matrix, inversion, inv...   \n",
       "2  [we, give, an, interpretation, of, a, class, o...   \n",
       "3  [levy, matrices, are, symmetric, random, matri...   \n",
       "4  [this, paper, deals, with, necessary, and, suf...   \n",
       "\n",
       "                                        strip_tokens  \n",
       "0  [differential, equations, spaces, operators, l...  \n",
       "1  [using, blockwise, matrix, inversion, inversio...  \n",
       "2  [give, interpretation, class, discrete, contin...  \n",
       "3  [levy, matrices, symmetric, random, matrices, ...  \n",
       "4  [paper, deals, necessary, sufficient, conditio...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['strip_tokens'] = df['tokens'].apply(stop_strip)\n",
    "df[['tokens', 'strip_tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = defaultdict(int)\n",
    "\n",
    "for text in df['strip_tokens']:\n",
    "    for word in text:\n",
    "        word_counter[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [key for key in word_counter.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16010"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make function for bagging tokens\n",
    "def bagger(text, keys):\n",
    "    bag = np.zeros(len(keys))\n",
    "    for word in text:\n",
    "        bag[keys.index(word)]+=1\n",
    "        #bag[np.where(keys==word)]+=1\n",
    "    \n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagger(df['strip_tokens'].iloc[0], keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bagger(df['strip_tokens'].iloc[0], keys=keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['strip_tokens'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bag_vec'] = df['strip_tokens'].apply(lambda x: bagger(x,keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 3., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 3., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_bag = np.stack(df['bag_vec'])\n",
    "big_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4462, 16010)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_bag.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "At this point, we have created our `bag of words`: i.e., an array where each row is a document (an abstract in our case), and each column corresponds to a token that occurs in some document. We can think of this array as our new dataframe on which to apply ML algorithms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute TF-IDF score for each document-term pair in this array:\n",
    "\n",
    "1) TF = term frequency, i.e. the number of appearances of the term in the document divided by the length of the document.\n",
    "2) IDF = inverse document frequency. This is the log of the ratio (total number of docs) / (number of docs containing the term)\n",
    "\n",
    "TF-IDF is the product of these two scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = np.zeros(big_bag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0326087 , 0.0326087 , 0.01086957, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.11538462, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00847458, 0.        , ..., 0.00847458, 0.00847458,\n",
       "        0.00847458]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs = big_bag/(np.sum(big_bag, axis=1).reshape(-1,1))\n",
    "tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = -np.log10(np.sum(1*(big_bag>0), axis=0)/big_bag.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.11805065, 0.92854382, 1.00706505, ..., 3.64952957, 3.64952957,\n",
       "       3.64952957])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfs*idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03645817, 0.0302786 , 0.01094636, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.11619981, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00786902, 0.        , ..., 0.03092822, 0.03092822,\n",
       "        0.03092822]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have converted our documents (abstracts) to vectors whose entries are TF-IDF scores relative to each term in our vocabulary. We can now apply dimension reduction before clustering, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
