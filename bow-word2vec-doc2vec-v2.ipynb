{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "697cff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from scipy import spatial\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim.downloader as api\n",
    "import gensim\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# from gensim import corpora, models, similarities\n",
    "#from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from multipledispatch import dispatch\n",
    "\n",
    "import arxiv\n",
    "from data_utils import format_query, query_to_df, clean_data, clean_authors\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a80f0333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_abstract</th>\n",
       "      <th>clean_authors</th>\n",
       "      <th>abstract_tokenized</th>\n",
       "      <th>abstract_reduced_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182244</th>\n",
       "      <td>1412.3275</td>\n",
       "      <td>Limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>We study the maximum number of limit cycles ...</td>\n",
       "      <td>2014-12-11</td>\n",
       "      <td>[['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>we study the maximum number of limit cycles th...</td>\n",
       "      <td>[['llibre', 'j', ''], ['pantazi', 'c', '']]</td>\n",
       "      <td>[we, study, the, maximum, number, of, limit, c...</td>\n",
       "      <td>[study, maximum, number, limit, cycles, bifurc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                              title  \\\n",
       "182244  1412.3275  Limit cycles bifurcating from a degenerate center   \n",
       "\n",
       "                                                 abstract update_date  \\\n",
       "182244    We study the maximum number of limit cycles ...  2014-12-11   \n",
       "\n",
       "                                       authors_parsed strip_cat  \\\n",
       "182244  [['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]      [DS]   \n",
       "\n",
       "                                              clean_title  \\\n",
       "182244  limit cycles bifurcating from a degenerate center   \n",
       "\n",
       "                                           clean_abstract  \\\n",
       "182244  we study the maximum number of limit cycles th...   \n",
       "\n",
       "                                      clean_authors  \\\n",
       "182244  [['llibre', 'j', ''], ['pantazi', 'c', '']]   \n",
       "\n",
       "                                       abstract_tokenized  \\\n",
       "182244  [we, study, the, maximum, number, of, limit, c...   \n",
       "\n",
       "                                  abstract_reduced_tokens  \n",
       "182244  [study, maximum, number, limit, cycles, bifurc...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load in the dataset\n",
    "## This file keeps the stopwords, but removes words of freq=1 in the corpus from the tokens\n",
    "#df = pd.read_parquet(\"./data/filter_20k_tokenized_stopwords.parquet\")\n",
    "\n",
    "## This file removes both stopwords and words of freq=1 in the corpus from the tokens\n",
    "df = pd.read_parquet(\"./data/filter_20k_tokenized.parquet\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "57e554ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_abstract</th>\n",
       "      <th>clean_authors</th>\n",
       "      <th>abstract_tokenized</th>\n",
       "      <th>abstract_reduced_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182244</td>\n",
       "      <td>1412.3275</td>\n",
       "      <td>Limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>We study the maximum number of limit cycles ...</td>\n",
       "      <td>2014-12-11</td>\n",
       "      <td>[['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>we study the maximum number of limit cycles th...</td>\n",
       "      <td>[['llibre', 'j', ''], ['pantazi', 'c', '']]</td>\n",
       "      <td>[we, study, the, maximum, number, of, limit, c...</td>\n",
       "      <td>[study, maximum, number, limit, cycles, bifurc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index         id  \\\n",
       "0          182244  1412.3275   \n",
       "\n",
       "                                               title  \\\n",
       "0  Limit cycles bifurcating from a degenerate center   \n",
       "\n",
       "                                            abstract update_date  \\\n",
       "0    We study the maximum number of limit cycles ...  2014-12-11   \n",
       "\n",
       "                                  authors_parsed strip_cat  \\\n",
       "0  [['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]      [DS]   \n",
       "\n",
       "                                         clean_title  \\\n",
       "0  limit cycles bifurcating from a degenerate center   \n",
       "\n",
       "                                      clean_abstract  \\\n",
       "0  we study the maximum number of limit cycles th...   \n",
       "\n",
       "                                 clean_authors  \\\n",
       "0  [['llibre', 'j', ''], ['pantazi', 'c', '']]   \n",
       "\n",
       "                                  abstract_tokenized  \\\n",
       "0  [we, study, the, maximum, number, of, limit, c...   \n",
       "\n",
       "                             abstract_reduced_tokens  \n",
       "0  [study, maximum, number, limit, cycles, bifurc...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "df = df.rename(columns={\"index\": \"original_index\"})\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cab1172a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['abstract_reduced_tokens'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b2f67990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_abstract</th>\n",
       "      <th>clean_authors</th>\n",
       "      <th>abstract_tokenized</th>\n",
       "      <th>abstract_reduced_tokens</th>\n",
       "      <th>abstract_reduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182244</td>\n",
       "      <td>1412.3275</td>\n",
       "      <td>Limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>We study the maximum number of limit cycles ...</td>\n",
       "      <td>2014-12-11</td>\n",
       "      <td>[['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>we study the maximum number of limit cycles th...</td>\n",
       "      <td>[['llibre', 'j', ''], ['pantazi', 'c', '']]</td>\n",
       "      <td>[we, study, the, maximum, number, of, limit, c...</td>\n",
       "      <td>[study, maximum, number, limit, cycles, bifurc...</td>\n",
       "      <td>study maximum number limit cycles bifurcate de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index         id  \\\n",
       "0          182244  1412.3275   \n",
       "\n",
       "                                               title  \\\n",
       "0  Limit cycles bifurcating from a degenerate center   \n",
       "\n",
       "                                            abstract update_date  \\\n",
       "0    We study the maximum number of limit cycles ...  2014-12-11   \n",
       "\n",
       "                                  authors_parsed strip_cat  \\\n",
       "0  [['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]      [DS]   \n",
       "\n",
       "                                         clean_title  \\\n",
       "0  limit cycles bifurcating from a degenerate center   \n",
       "\n",
       "                                      clean_abstract  \\\n",
       "0  we study the maximum number of limit cycles th...   \n",
       "\n",
       "                                 clean_authors  \\\n",
       "0  [['llibre', 'j', ''], ['pantazi', 'c', '']]   \n",
       "\n",
       "                                  abstract_tokenized  \\\n",
       "0  [we, study, the, maximum, number, of, limit, c...   \n",
       "\n",
       "                             abstract_reduced_tokens  \\\n",
       "0  [study, maximum, number, limit, cycles, bifurc...   \n",
       "\n",
       "                                    abstract_reduced  \n",
       "0  study maximum number limit cycles bifurcate de...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rejoin the tokens for use with some models\n",
    "df['abstract_reduced'] = df['abstract_reduced_tokens'].apply(\" \".join)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae23961",
   "metadata": {},
   "source": [
    "Now we define the functions for the various models that we will need to compute similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bde02c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A function to get the vector norm\n",
    "def norm(u):\n",
    "    return np.sqrt(np.sum(np.power(u,2)))\n",
    "\n",
    "## A function to get the cosine similarity\n",
    "def cos_sim(u,v):\n",
    "    if norm(u)*norm(v) > 0:\n",
    "        return (u.dot(v))/(norm(u)*norm(v))\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a87baedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Auxilary function\n",
    "\"\"\"\n",
    "    Display the top n most similar article in the dataset to an \n",
    "    article that is already in the dataset.\n",
    "    \n",
    "    Inputs:\n",
    "    df: a DataFrame with all of the articles\n",
    "    df_sim: a DataFrame with the top n most similar articles to article_index \n",
    "            and their computed cosine similarities\n",
    "            \n",
    "    article_index: an integer that is an index of an article in the DataFrame;\n",
    "                   should range from 0 to len(df)-1 \n",
    "\"\"\"\n",
    "def print_similar(df, df_sim, article_index):\n",
    "    \n",
    "    print(\"The top\", len(df_sim), \"articles most similar to the article \\n\\n\", \n",
    "            article_index, \".\", df['title'][article_index])\n",
    "    print(\"-----------------------------------------------------\\n\")\n",
    "    \n",
    "    i = 1\n",
    "    for index in df_sim.index.values: \n",
    "        print(i, \".\", \"(\", index , \")\", df['title'][index], \n",
    "          \", Cosine Similiarity=\", np.round(df_sim['Cosine Similarity'][index], 3))\n",
    "        print()\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01512dac",
   "metadata": {},
   "source": [
    "### Some functions for returning the top $n$ most similar papers to a paper already in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bc93cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(x):\n",
    "    temp = x.copy()\n",
    "    for i in range(len(temp)):\n",
    "        if np.isnan(temp[i]):\n",
    "            temp[i] = -1\n",
    "    return temp\n",
    "\n",
    "## For use with CountVectorizer and TfidVectorizer\n",
    "\"\"\"\n",
    "    Prints the top n most similar article titles from the dataframe\n",
    "    to the input article by calculating their cosine similarity.\n",
    "    \n",
    "    Inputs:\n",
    "    df: a DataFrame with all of the articles\n",
    "    df_vectorized: a dataframe of word frequencies\n",
    "    article_index: index of the article we want to compare cosine similarities to\n",
    "    n: number \"n\" number of most similar articles to search for\n",
    "\"\"\"\n",
    "@dispatch(pd.core.frame.DataFrame, pd.core.frame.DataFrame, int, int)\n",
    "\n",
    "def get_n_most_similar(df, df_vectorized, article_index , n):\n",
    "    \n",
    "    print(\"Using a CountVectorizer or TfidVectorizer.\\n\")\n",
    "    \n",
    "    # Calculate the cosine similariy scores for the i-th article in the dataset\n",
    "    cosine_sim_list = np.zeros(len(df))\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        if i != article_index:\n",
    "\n",
    "            text_to_vector_v1 = df_vectorized.iloc[i].values\n",
    "            text_to_vector_v2 = df_vectorized.iloc[article_index].values\n",
    "            \n",
    "            sim_scores = cos_sim(text_to_vector_v1, text_to_vector_v2)\n",
    "            cosine_sim_list[i] = sim_scores\n",
    "   \n",
    "    ## Caution: there may be some cosine sims with value NaN\n",
    "    cosine_sim_list = remove_nan(cosine_sim_list)\n",
    "    ## Getting indices of n maximum values\n",
    "    x = np.argsort(cosine_sim_list)[::-1][:n]\n",
    "     \n",
    "    \n",
    "    ## Create a dataframe with the results\n",
    "    df_sim = pd.DataFrame(columns=df.columns)\n",
    "    df_sim['Cosine Similarity'] = []\n",
    "   \n",
    "    for index in x:\n",
    "        df_sim.loc[index] = df.iloc[index]\n",
    "        # df_sim.loc[index] = df.iloc[index]\n",
    "       # df_sim.iloc[index]['Cosine Similarity'] = cosine_sim_list[index]\n",
    "        df_sim.at[index, 'Cosine Similarity'] = cosine_sim_list[index]\n",
    "          \n",
    "    return df_sim, article_index\n",
    "\n",
    "###################################################################\n",
    "\n",
    "## For use with Word2Vec\n",
    "## Word2Vec supports a function called n_similarity\n",
    "\"\"\"\n",
    "    Prints the top n most similar (by cosine similarity)\n",
    "    article titles to article_index. \n",
    "    \n",
    "    Inputs: \n",
    "    model: a trained Word2Vec model\n",
    "    df: a DataFrame with all of the articles\n",
    "    article_index: an integer that is an index of an article in the DataFrame;\n",
    "                   should range from 0 to len(df)-1 \n",
    "    n: number \"n\" number of most similar articles to search for\n",
    "    \n",
    "\"\"\"\n",
    "@dispatch(gensim.models.keyedvectors.KeyedVectors, pd.core.frame.DataFrame, int, int)\n",
    "\n",
    "def get_n_most_similar(model, df, article_index , n):\n",
    "    \n",
    "    print(\"Using Word2Vec.\\n\")\n",
    "     \n",
    "    cosine_sim_list = np.zeros(len(df))\n",
    "\n",
    "    for i in range(len(df)):      \n",
    "        # Calculate the cosine similariy scores with the i-th article in the dataset\n",
    "        \n",
    "        if i != article_index and len(df['abstract_reduced_tokens'][i]) != 0:\n",
    "        # The difference here is the use of the n_similarity function\n",
    "            cosine_sim_list[i]  = model.n_similarity(df['abstract_reduced_tokens'][article_index], \n",
    "                                                     df['abstract_reduced_tokens'][i])\n",
    "        \n",
    "    ## Caution: there may be some cosine sims with value NaN\n",
    "    cosine_sim_list = remove_nan(cosine_sim_list)\n",
    "    ## Getting indices of the n maximum values\n",
    "    x = np.argsort(cosine_sim_list)[::-1][:n]\n",
    "            \n",
    "    ## Create a dataframe with the results\n",
    "    df_sim = pd.DataFrame(columns=df.columns)\n",
    "    df_sim['Cosine Similarity'] = []\n",
    "    \n",
    "    for index in x:\n",
    "        df_sim.loc[index] = df.iloc[index].copy()\n",
    "        #df_sim.loc[index] = df.iloc[index]\n",
    "        #df_sim['Cosine Similarity'].loc[index] = cosine_sim_list[index]\n",
    "        df_sim.at[index, 'Cosine Similarity'] = cosine_sim_list[index]\n",
    "        \n",
    "    return df_sim, article_index\n",
    "\n",
    "###################################################################\n",
    "\n",
    "## Doc2Vec supports a function called most_similar \n",
    "\"\"\"\n",
    "    Prints the top n most similar (by cosine similarity)\n",
    "    article titles to article_index.    \n",
    "    \n",
    "    Inputs: \n",
    "    model: a trained Doc2Vec model\n",
    "    df: a DataFrame with all of the articles\n",
    "    article_index: an integer that is an index of an article in the DataFrame;\n",
    "                   should range from 0 to len(df)-1 \n",
    "    n: number \"n\" number of most similar articles to search for\n",
    "\"\"\"\n",
    "@dispatch(gensim.models.doc2vec.Doc2Vec, pd.core.frame.DataFrame, int, int)\n",
    "\n",
    "def get_n_most_similar(model, df, article_index , n):\n",
    "    \n",
    "    print(\"Using Doc2Vec\\n\")\n",
    "    \n",
    "    # dv.most_similar returns the same values as d2v_model.dv.similarity(i, j)\n",
    "    topn = model.dv.most_similar(article_index, topn=n)\n",
    "   \n",
    "    article_indices = [x[0] for x in topn]\n",
    "    cos_sims = [x[1] for x in topn]\n",
    "    \n",
    "    ## Create a dataframe with the results\n",
    "    df_sim = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    for index in article_indices:\n",
    "       # df_sim.loc[index] = df.iloc[index].copy()\n",
    "        df_sim.loc[index] = df.iloc[index]\n",
    "    \n",
    "    df_sim['Cosine Similarity'] = cos_sims\n",
    "        \n",
    "    return df_sim, article_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb51a9",
   "metadata": {},
   "source": [
    "### Some functions for returning the top $n$ most similar papers to a paper NOT already in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bade6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b2e9ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "27cfd6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For use with Word2Vec\n",
    "## Word2Vec supports a function called n_similarity\n",
    "\n",
    "## user_vector: the tokenized and cleaned abstract of the user's input\n",
    "\n",
    "@dispatch(gensim.models.keyedvectors.KeyedVectors, pd.core.frame.DataFrame, list, int)\n",
    "def get_n_most_similar(model, df, user_tokens, n):\n",
    "    \n",
    "    print(\"Using Word2Vec\\n\")\n",
    "     \n",
    "    cosine_sim_list = np.zeros(len(df))\n",
    "\n",
    "    for i in range(len(df)):      \n",
    "        # Calculate the cosine similariy scores with the i-th article in the dataset\n",
    "        # The difference here is the use of the n_similarity function\n",
    "        cosine_sim_list[i]  = model.n_similarity(user_tokens, df['abstract_reduced_tokens'][i])\n",
    "        \n",
    "    ## Getting indices of the n maximum values\n",
    "    x = np.argsort(cosine_sim_list)[::-1][:n]\n",
    "            \n",
    "    ## Create a dataframe with the results\n",
    "    df_sim = pd.DataFrame(columns=df.columns)\n",
    "    df_sim['Cosine Similarity'] = []\n",
    "    \n",
    "    for index in x:\n",
    "        df_sim.loc[index] = df.iloc[index].copy() \n",
    "        df_sim['Cosine Similarity'].loc[index] = cosine_sim_list[index]\n",
    "        \n",
    "    return df_sim\n",
    "\n",
    "###################################################################\n",
    "\n",
    "## Doc2Vec Recommender\n",
    "## use the infer_vector function (may not be necessary?)\n",
    "## Choose the first paper in our dataset\n",
    "\n",
    "@dispatch(gensim.models.doc2vec.Doc2Vec, pd.core.frame.DataFrame, list, int)\n",
    "\n",
    "def get_n_most_similar(d2v_model, df, user_vector, n):\n",
    "    print(\"Using Doc2Vec\\n\")\n",
    "    \n",
    "    topn = d2v_model.dv.most_similar([user_vector], topn=n)\n",
    "    \n",
    "    article_indices = [x[0] for x in topn]\n",
    "    cos_sims = [x[1] for x in topn]\n",
    "    \n",
    "    ## Create a dataframe with the results\n",
    "    df_sim = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    for index in article_indices:\n",
    "        df_sim.loc[index] = df.iloc[index].copy()\n",
    "    \n",
    "    df_sim['Cosine Similarity'] = cos_sims\n",
    "        \n",
    "    return df_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1b1c75",
   "metadata": {},
   "source": [
    "### Functions for finding the top $n$ recommendations based on $m$ user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6d04b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Auxiliary function\n",
    "\"\"\"\n",
    "    A nicer way to display the recommendations to the user.\n",
    "    \n",
    "    df_user: the dataset of articles the user has input\n",
    "    df_results: results of similar articles based on \n",
    "\"\"\"\n",
    "def display_results(df_results, df_user):\n",
    "    print(\"The top\", len(df_results), \"articles most similar to the articles: \\n\\n\")   \n",
    "   ## print(df_user.index.values)\n",
    "    ## Get the titles\n",
    "    i = 0\n",
    "    for i in range(len(df_user)):\n",
    "        title = df_user.iloc[i]['title']\n",
    "        print(i+1, \".\", title)  \n",
    "        i = i + 1\n",
    "        \n",
    "    print(\"\\n#############################################################\\n\")\n",
    "    \n",
    "    for i in range(len(df_results)):\n",
    "       \n",
    "        match_index = df_results.index.values[i]\n",
    "        title = df_results.loc[match_index]['title']\n",
    "        authors = df_results.loc[match_index]['authors_parsed']\n",
    "        abstract = df_results.loc[match_index]['abstract']\n",
    "      #  link = df_results.loc[match_index]['entry_id'] \n",
    "        cos_sim = df_results.loc[match_index]['Cosine Similarity']\n",
    "        \n",
    "        print(i+1, \".\", \"(\", match_index, \")\", title, \n",
    "              \"\\n [ Cosine Similarity=\", np.round(cos_sim, 3) ,\"]\\n\")\n",
    "     #   print(\"\\n\", authors)\n",
    "        print(\"\\n\", abstract)\n",
    "      #  print(\"\\n\", link) \n",
    "        print(\"\\n-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8cfba436",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For use with Word2Vec\n",
    "\"\"\"\n",
    "    Returns a dataframe of the top n most similar (by cosine similarity)\n",
    "    article titles to the user's inputs. \n",
    "    \n",
    "    Inputs:\n",
    "    model: a trained Word2Vec model\n",
    "    df: a DataFrame with all of the articles  \n",
    "    df_user: a dataframe of the user's article inputs   \n",
    "    n: number of recommendations to return \n",
    "\"\"\"\n",
    "@dispatch(gensim.models.keyedvectors.KeyedVectors, pd.core.frame.DataFrame,\n",
    "                                              pd.core.frame.DataFrame, int)\n",
    "\n",
    "def n_recommendations(model, df, df_user, n):\n",
    "    \n",
    "    print(\"Using Word2Vec\")\n",
    "    \n",
    "    ## Create a DataFrame to store the similarity results     \n",
    "    df_sim_scores = pd.DataFrame(columns=df.columns)\n",
    "    df_sim_scores['Cosine Similarity'] = []\n",
    "    \n",
    "    for article_index in df_user.index.values: \n",
    "    \n",
    "        user_abstract = df_user['abstract_tokenized'][article_index]\n",
    "    \n",
    "        for i in range(len(df)): \n",
    "            if len(df['abstract_reduced_tokens'][i]) != 0:\n",
    "                # Calculate the cosine similarity scores with the i-th article in the dataset\n",
    "                sim_score = model.n_similarity(user_abstract, df['abstract_reduced_tokens'][i])\n",
    "             #   df_sim_scores.loc[len(df_sim_scores)] = df.iloc[i].copy()\n",
    "                df_sim_scores.loc[len(df_sim_scores)] = df.iloc[i]\n",
    "             #   df_sim_scores['Cosine Similarity'].loc[i] = sim_score\n",
    "                df_sim_scores.at[i, 'Cosine Similarity'] = sim_score\n",
    "            \n",
    "  #  print(\"after computing, length df_sim_score =\", len(df_sim_scores))\n",
    "    \n",
    "    ## Sort the cosine similarity scores in the dataframe\n",
    "    df_sim_scores = df_sim_scores.sort_values(by=['Cosine Similarity'], ascending=False)\n",
    "        \n",
    "    ## Now check for duplicate articles indices and keep the last index\n",
    "    ## By default, it will keep the first row and remove the redundant rows.\n",
    "        \n",
    "    df_sim_scores = df_sim_scores.drop_duplicates(subset=['id'])\n",
    "       \n",
    "  #  print(\"\\n after dropping,  length df_sim_score =\", len(df_sim_scores))\n",
    "    \n",
    "     ## Get the first n articles in the dataframe\n",
    "    df_top_n = df_sim_scores.head(n)\n",
    "\n",
    "    return df_top_n, df_user\n",
    "\n",
    "###################################################################\n",
    "\n",
    "\"\"\"\n",
    "    Returns a dataframe of the top n most similar (by cosine similarity)\n",
    "    article titles to the user's inputs. \n",
    "    \n",
    "    Inputs:\n",
    "    model: a trained Doc2Vec model\n",
    "    df: a DataFrame with all of the articles  \n",
    "    df_user: a dataframe of the user's article inputs   \n",
    "    n: number of recommendations to return \n",
    "\"\"\"\n",
    "@dispatch(gensim.models.doc2vec.Doc2Vec, pd.core.frame.DataFrame,\n",
    "                                      pd.core.frame.DataFrame, int)\n",
    "\n",
    "def n_recommendations(model, df, df_user, n):\n",
    "    \n",
    "    print(\"Using Doc2Vec\")\n",
    "    \n",
    "    ## Create a DataFrame to store the similarity results     \n",
    "    df_sim_scores = pd.DataFrame(columns=df.columns)\n",
    "    df_sim_scores['Cosine Similarity'] = []\n",
    "    \n",
    "    for article_index in df_user.index.values: \n",
    "    \n",
    "        user_abstract = df_user['abstract_tokenized'][article_index]\n",
    "        \n",
    "      #  print(\"type(user_abstract)\", type(user_abstract))\n",
    "        \n",
    "        ## Infer a vector for a new document    \n",
    "        ## Is this necessary?\n",
    "        # user_vector = d2v_model.infer_vector(user_abstract)\n",
    "        \n",
    "       # print(\"type(user_vector)\", type(user_vector))\n",
    "    \n",
    "        for i in range(len(df)):      \n",
    "        # Calculate the cosine similarity scores with the i-th article in the dataset\n",
    "               \n",
    "           # sim_score = model.n_similarity(user_abstract, df['abstract_reduced_tokens'][i])\n",
    "            \n",
    "            vector = df['abstract_reduced_tokens'][i] \n",
    "            \n",
    "           # print(\"df['abstract_reduced_tokens'][i]\", type(vector))\n",
    "            if len(vector) != 0:\n",
    "                sim_score = model.wv.n_similarity(user_abstract, vector)\n",
    "\n",
    "              #  sim_score = model.dv.similarity(user_vector, i)\n",
    "             #   df_sim_scores.loc[len(df_sim_scores)] = df.iloc[i].copy()\n",
    "                df_sim_scores.loc[len(df_sim_scores)] = df.iloc[i]\n",
    "              #  df_sim_scores['Cosine Similarity'].loc[i] = sim_score\n",
    "                df_sim_scores.at[i, 'Cosine Similarity'] = sim_score\n",
    "            \n",
    "   # print(\"after computing, length df_sim_score =\", len(df_sim_scores))\n",
    "    \n",
    "    ## Sort the cosine similarity scores in the dataframe\n",
    "    df_sim_scores = df_sim_scores.sort_values(by=['Cosine Similarity'], ascending=False)\n",
    "        \n",
    "    ## Now check for duplicate articles indices and keep the last index\n",
    "    ## By default, it will keep the first row and remove the redundant rows.\n",
    "        \n",
    "    df_sim_scores = df_sim_scores.drop_duplicates(subset=['id'])\n",
    "       \n",
    "  #  print(\"\\n after dropping,  length df_sim_score =\", len(df_sim_scores))\n",
    "    \n",
    "     ## Get the first n articles in the dataframe\n",
    "    df_top_n = df_sim_scores.head(n)\n",
    "\n",
    "    return df_top_n, df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077b489",
   "metadata": {},
   "source": [
    "## The models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d33583c",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "\n",
    "Creates a matrix with documents and token counts (bag of terms/tokens) therefore it is also known as document term matrix (dtm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "03446951",
   "metadata": {},
   "outputs": [],
   "source": [
    "## max_df: When building the vocabulary ignore terms that have a document frequency \n",
    "##         strictly higher than the given threshold (corpus-specific stop words).\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer=\"word\", \n",
    "                                tokenizer=nltk.word_tokenize,\n",
    "                                preprocessor=None, \n",
    "                               # stop_words='english', \n",
    "                                max_features=2500,\n",
    "                                ngram_range=(1,3))\n",
    "                                    ##  max_df=.9\n",
    "    \n",
    "bow = count_vectorizer.fit_transform(df['abstract_reduced'])\n",
    "\n",
    "df_bow = pd.DataFrame(bow.toarray(),\n",
    "                      columns = count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b552ece7",
   "metadata": {},
   "source": [
    "### TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "02ac00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_vectorizer = TfidfVectorizer(analyzer=\"word\", \n",
    "                                tokenizer=nltk.word_tokenize,\n",
    "                                preprocessor=None, \n",
    "                             #   stop_words='english', \n",
    "                                max_features=2500,\n",
    "                                ngram_range=(1,3))\n",
    "                                    ##  max_df=.9\n",
    "    \n",
    "tfid = tfid_vectorizer.fit_transform(df['abstract_reduced'])\n",
    "\n",
    "df_tfid = pd.DataFrame(tfid.toarray(),\n",
    "                      columns = tfid_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc1eba",
   "metadata": {},
   "source": [
    "### Word2Vec \n",
    "\n",
    "We use a pretrained model for better results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7da1a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load word2vec model, here GoogleNews is used\n",
    "## The file must be previously downloaded\n",
    "## The size of the vectors is 300\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', \n",
    "                                                        binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7be84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8f7e676",
   "metadata": {},
   "source": [
    "### Doc2Vec "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef82edf",
   "metadata": {},
   "source": [
    "There are two approaches to the Doc2Vec model, (1) distributed bag of words and (2) distributed memory models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "50c9b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rather than a list of tokenized docs Doc2Vec requires tagged lists of tokens\n",
    "# that's because the model needs to keep track of the documents.\n",
    "summaries = [TaggedDocument(doc,[i]) for i, doc in enumerate(df['abstract_reduced_tokens'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed8ef95",
   "metadata": {},
   "source": [
    "#### Doc2Vec using Distributed Bag of Words\n",
    "\n",
    "Word2Vec was trained to model the probability that a randomly chosen word was a context word of the target word. With distributed bag of words the idea is to train a classifier network to model the probability that a given word is in the document, so in essence we're modeling the word distribution of the document rather than the contextual distribution of a target word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "167ab2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we train the Doc2Vec models\n",
    "\n",
    "# dm = 1 or 0 (optional) – Defines the training algorithm. \n",
    "# If dm=1, ‘distributed memory’ (PV-DM) is used. \n",
    "# Otherwise, distributed bag of words (PV-DBOW) is employed.\n",
    "\n",
    "# vector_size - Dimensionality of the feature vectors.\n",
    "\n",
    "# window -  The maximum distance between the current and \n",
    "# predicted word within a sentence.\n",
    "\n",
    "# min_count - require words to show up a minimum of 2 times\n",
    "# iscard words with very few occurrences. (Without a variety of representative \n",
    "# examples, retaining such infrequent words can often make a model worse!)\n",
    "\n",
    "\n",
    "d2v_model_bow = Doc2Vec(documents = summaries,\n",
    "                    dm = 0, ## use distributed bag of words (PV-DBOW) \n",
    "                    vector_size = 300, \n",
    "                    window = 2, \n",
    "                    min_count = 2,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "214f2dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Doc2Vec using Distributed Memory\n",
    "d2v_model_dm = Doc2Vec(documents = summaries,\n",
    "                    dm = 1, ## use distributed memory\n",
    "                    vector_size = 300, \n",
    "                    window = 2, \n",
    "                    min_count = 2,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db6595c",
   "metadata": {},
   "source": [
    "#### Sanity check\n",
    "\n",
    "We can  see how \"good\" the embedding is by looping through the abstracts and recording the similarity rank of the actual abstract embedding to the inferred embedding.\n",
    "\n",
    "Then, we can calculate the fraction of documents whose rank was 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4e357d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    To see how \"good\" the Doc2Vec embedding is loop through the abstracts \n",
    "    and record the similarity rank of the actual abstract embedding to the \n",
    "    inferred embedding.\n",
    "    Then, calculate and print the fraction of documents whose rank was 0.\n",
    "\"\"\"\n",
    "def check_doc2vec_embedding(d2v_model):\n",
    "    # We'll loop through all of the documents\n",
    "    # and record the similarity rank to their inferred vector\n",
    "    summary_ranks = []\n",
    "\n",
    "    # for each document\n",
    "    for summary in summaries:\n",
    "        # get the inferred vector\n",
    "        inferred_vec = d2v_model.infer_vector(summary.words)\n",
    "        # find the most similar vectors\n",
    "        sims = d2v_model.dv.most_similar([inferred_vec], topn=len(summaries))\n",
    "    \n",
    "    # loop through those vectors\n",
    "        for i in range(len(sims)):\n",
    "            # find the rank of the document\n",
    "            if summary.tags[0] == sims[i][0]:\n",
    "                # record it\n",
    "                summary_ranks.append(i)\n",
    "                \n",
    "    # the fraction of documents whose rank was 0           \n",
    "    rank_0 = np.sum(np.array(summary_ranks)==0)/len(summary_ranks)\n",
    "    print(\"The fraction of documents whose rank is 0 is\", np.round(rank_0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b7311e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Doc2Vec Model (Dist. Bag of Words)-----------------\n",
      "\n",
      "The fraction of documents whose rank is 0 is 0.992\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------- Doc2Vec Model (Dist. Bag of Words)-----------------\\n\")\n",
    "check_doc2vec_embedding(d2v_model_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b22cc6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Doc2Vec Model (Dist. Memory)-----------------\n",
      "\n",
      "The fraction of documents whose rank is 0 is 0.992\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------- Doc2Vec Model (Dist. Memory)-----------------\\n\")\n",
    "check_doc2vec_embedding(d2v_model_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a77f0a",
   "metadata": {},
   "source": [
    "These models seem reasonable!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3168f309",
   "metadata": {},
   "source": [
    "#### Compare results of CountVectorizer, TfidVectorizer, Word2Vec, Doc2Vec for articles within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "93ecd6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a CountVectorizer or TfidVectorizer.\n",
      "\n",
      "Using a CountVectorizer or TfidVectorizer.\n",
      "\n",
      "Using Word2Vec.\n",
      "\n",
      "Using Doc2Vec\n",
      "\n",
      "Using Doc2Vec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Similarity scores for the the first article in the DataFrame\n",
    "\n",
    "## Using CountVectorizer\n",
    "df_cv = get_n_most_similar(df.copy(), df_bow, 1, 5)[0]\n",
    "\n",
    "# Using TfidVectorizer\n",
    "df_tf = get_n_most_similar(df.copy(), df_tfid, 0, 5)[0]\n",
    "\n",
    "# Using Word2Vec\n",
    "df_wv = get_n_most_similar(w2v_model, df, 0, 5)[0]\n",
    "\n",
    "# Using Doc2Vec with Distributed BOW\n",
    "df_dv_bow = get_n_most_similar(d2v_model_bow, df, 0, 5)[0]\n",
    "\n",
    "# Using Doc2Vec with Distributed Memory\n",
    "df_dv_dm = get_n_most_similar(d2v_model_dm, df, 0, 5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "25fa1d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Count Vectorizer ---------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8939</th>\n",
       "      <td>301296</td>\n",
       "      <td>Grazingsliding bifurcations creating infinitel...</td>\n",
       "      <td>As the parameters of a piecewisesmooth syste...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Simpson', 'David J. W.', '']]</td>\n",
       "      <td>0.417186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>339095</td>\n",
       "      <td>On the bifurcation diagram of the capillarygra...</td>\n",
       "      <td>We study the bifurcation of periodic travell...</td>\n",
       "      <td>[AP]</td>\n",
       "      <td>[['Ehrnström', 'Mats', ''], ['Johnson', 'Mathe...</td>\n",
       "      <td>0.412479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>373712</td>\n",
       "      <td>Numerical continuation for a fastreaction syst...</td>\n",
       "      <td>In this paper we investigate the bifurcation...</td>\n",
       "      <td>[AP]</td>\n",
       "      <td>[['Kuehn', 'Christian', ''], ['Soresina', 'Cin...</td>\n",
       "      <td>0.379043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>217240</td>\n",
       "      <td>The structure of modelocking regions of piecew...</td>\n",
       "      <td>The modelocking regions of a dynamical syste...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Simpson', 'David J. W.', '']]</td>\n",
       "      <td>0.369274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14098</th>\n",
       "      <td>75053</td>\n",
       "      <td>Unfolding a CodimensionTwo, Discontinuous, And...</td>\n",
       "      <td>We present an unfolding of the codimensiontw...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....</td>\n",
       "      <td>0.360492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      original_index                                              title  \\\n",
       "8939          301296  Grazingsliding bifurcations creating infinitel...   \n",
       "3181          339095  On the bifurcation diagram of the capillarygra...   \n",
       "9980          373712  Numerical continuation for a fastreaction syst...   \n",
       "4123          217240  The structure of modelocking regions of piecew...   \n",
       "14098          75053  Unfolding a CodimensionTwo, Discontinuous, And...   \n",
       "\n",
       "                                                abstract strip_cat  \\\n",
       "8939     As the parameters of a piecewisesmooth syste...      [DS]   \n",
       "3181     We study the bifurcation of periodic travell...      [AP]   \n",
       "9980     In this paper we investigate the bifurcation...      [AP]   \n",
       "4123     The modelocking regions of a dynamical syste...      [DS]   \n",
       "14098    We present an unfolding of the codimensiontw...      [DS]   \n",
       "\n",
       "                                          authors_parsed Cosine Similarity  \n",
       "8939                    [['Simpson', 'David J. W.', '']]          0.417186  \n",
       "3181   [['Ehrnström', 'Mats', ''], ['Johnson', 'Mathe...          0.412479  \n",
       "9980   [['Kuehn', 'Christian', ''], ['Soresina', 'Cin...          0.379043  \n",
       "4123                    [['Simpson', 'David J. W.', '']]          0.369274  \n",
       "14098  [['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....          0.360492  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--------------------- Count Vectorizer ---------------------\\n\")\n",
    "df_cv[['original_index', 'title', 'abstract', 'strip_cat', 'authors_parsed', 'Cosine Similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ee2b9b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Tfid Vectorizer ---------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9508</th>\n",
       "      <td>315961</td>\n",
       "      <td>Planar Semiquasi Homogeneous Polynomial differ...</td>\n",
       "      <td>This paper study the planar semiquasi homoge...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Tian', 'Yuzhou', ''], ['Liang', 'Haihua', '']]</td>\n",
       "      <td>0.405092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15936</th>\n",
       "      <td>329106</td>\n",
       "      <td>Bifurcation of limit cycles from a quadratic g...</td>\n",
       "      <td>In this paper, we generalize the PicardFuchs...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Yang', 'Jihua', '']]</td>\n",
       "      <td>0.325908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17297</th>\n",
       "      <td>169000</td>\n",
       "      <td>Solution of the parametric center problem for ...</td>\n",
       "      <td>The Abel differential equation  with  is sai...</td>\n",
       "      <td>[CA, DS]</td>\n",
       "      <td>[['Pakovich', 'Fedor', '']]</td>\n",
       "      <td>0.32451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13706</th>\n",
       "      <td>511903</td>\n",
       "      <td>A sufficient and necessary condition of genera...</td>\n",
       "      <td>The aim of this paper is to give a sufficien...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Chen', 'Hebai', ''], ['Li', 'Zhijie', ''], ...</td>\n",
       "      <td>0.309687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>408265</td>\n",
       "      <td>The local period function for Hamiltonian syst...</td>\n",
       "      <td>In the first part of the paper we develop a ...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Buzzi', 'Claudio A.', ''], ['Carvalho', 'Ya...</td>\n",
       "      <td>0.301153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      original_index                                              title  \\\n",
       "9508          315961  Planar Semiquasi Homogeneous Polynomial differ...   \n",
       "15936         329106  Bifurcation of limit cycles from a quadratic g...   \n",
       "17297         169000  Solution of the parametric center problem for ...   \n",
       "13706         511903  A sufficient and necessary condition of genera...   \n",
       "4796          408265  The local period function for Hamiltonian syst...   \n",
       "\n",
       "                                                abstract strip_cat  \\\n",
       "9508     This paper study the planar semiquasi homoge...      [DS]   \n",
       "15936    In this paper, we generalize the PicardFuchs...      [DS]   \n",
       "17297    The Abel differential equation  with  is sai...  [CA, DS]   \n",
       "13706    The aim of this paper is to give a sufficien...      [DS]   \n",
       "4796     In the first part of the paper we develop a ...      [DS]   \n",
       "\n",
       "                                          authors_parsed Cosine Similarity  \n",
       "9508   [['Tian', 'Yuzhou', ''], ['Liang', 'Haihua', '']]          0.405092  \n",
       "15936                            [['Yang', 'Jihua', '']]          0.325908  \n",
       "17297                        [['Pakovich', 'Fedor', '']]           0.32451  \n",
       "13706  [['Chen', 'Hebai', ''], ['Li', 'Zhijie', ''], ...          0.309687  \n",
       "4796   [['Buzzi', 'Claudio A.', ''], ['Carvalho', 'Ya...          0.301153  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--------------------- Tfid Vectorizer ---------------------\\n\")\n",
    "df_tf[['original_index', 'title', 'abstract', 'strip_cat', 'authors_parsed', 'Cosine Similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6eeacf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Word2Vec Model ---------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>158258</td>\n",
       "      <td>Topology trivialization and large deviations f...</td>\n",
       "      <td>Finding the global minimum of a cost functio...</td>\n",
       "      <td>[MP, OC]</td>\n",
       "      <td>[['Fyodorov', 'Yan V', ''], ['Doussal', 'Pierr...</td>\n",
       "      <td>0.884011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>107803</td>\n",
       "      <td>Continuous Limits of Classical Repeated Intera...</td>\n",
       "      <td>We consider the physical model of a classica...</td>\n",
       "      <td>[MP, PR]</td>\n",
       "      <td>[['Deschamps', 'Julien', '']]</td>\n",
       "      <td>0.880297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19029</th>\n",
       "      <td>53103</td>\n",
       "      <td>Phase portraits for quadratic homogeneous poly...</td>\n",
       "      <td>Let X be a homogeneous polynomial vector fie...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Llibre', 'Jaume', ''], ['Pessoa', 'Claudio'...</td>\n",
       "      <td>0.878772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9508</th>\n",
       "      <td>315961</td>\n",
       "      <td>Planar Semiquasi Homogeneous Polynomial differ...</td>\n",
       "      <td>This paper study the planar semiquasi homoge...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Tian', 'Yuzhou', ''], ['Liang', 'Haihua', '']]</td>\n",
       "      <td>0.877008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18932</th>\n",
       "      <td>365655</td>\n",
       "      <td>Invariant tori, actionangle variables and phas...</td>\n",
       "      <td>We study the classical RajeevRanken model, a...</td>\n",
       "      <td>[DS, MP]</td>\n",
       "      <td>[['Krishnaswami', 'Govind S.', ''], ['Vishnu',...</td>\n",
       "      <td>0.875581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      original_index                                              title  \\\n",
       "6108          158258  Topology trivialization and large deviations f...   \n",
       "13151         107803  Continuous Limits of Classical Repeated Intera...   \n",
       "19029          53103  Phase portraits for quadratic homogeneous poly...   \n",
       "9508          315961  Planar Semiquasi Homogeneous Polynomial differ...   \n",
       "18932         365655  Invariant tori, actionangle variables and phas...   \n",
       "\n",
       "                                                abstract strip_cat  \\\n",
       "6108     Finding the global minimum of a cost functio...  [MP, OC]   \n",
       "13151    We consider the physical model of a classica...  [MP, PR]   \n",
       "19029    Let X be a homogeneous polynomial vector fie...      [DS]   \n",
       "9508     This paper study the planar semiquasi homoge...      [DS]   \n",
       "18932    We study the classical RajeevRanken model, a...  [DS, MP]   \n",
       "\n",
       "                                          authors_parsed Cosine Similarity  \n",
       "6108   [['Fyodorov', 'Yan V', ''], ['Doussal', 'Pierr...          0.884011  \n",
       "13151                      [['Deschamps', 'Julien', '']]          0.880297  \n",
       "19029  [['Llibre', 'Jaume', ''], ['Pessoa', 'Claudio'...          0.878772  \n",
       "9508   [['Tian', 'Yuzhou', ''], ['Liang', 'Haihua', '']]          0.877008  \n",
       "18932  [['Krishnaswami', 'Govind S.', ''], ['Vishnu',...          0.875581  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--------------------- Word2Vec Model ---------------------\\n\")\n",
    "df_wv[['original_index', 'title', 'abstract', 'strip_cat', 'authors_parsed', 'Cosine Similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "800695bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Doc2Vec Model (Dist. Bag of Words)-----------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>63325</td>\n",
       "      <td>Planar polynomial vector fields having a polyn...</td>\n",
       "      <td>We consider in this work planar polynomial d...</td>\n",
       "      <td>[CA, DS]</td>\n",
       "      <td>[['Garcia', 'Belen', ''], ['Giacomini', 'Hecto...</td>\n",
       "      <td>0.597346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10619</th>\n",
       "      <td>468612</td>\n",
       "      <td>Rational integrals of 2dimensional geodesic fl...</td>\n",
       "      <td>This paper is devoted to searching for Riema...</td>\n",
       "      <td>[DS, AP, DG]</td>\n",
       "      <td>[['Agapov', 'Sergei', '', '1 and 2'], ['Shubin...</td>\n",
       "      <td>0.531299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10096</th>\n",
       "      <td>325855</td>\n",
       "      <td>Averaging theory at any order for computing li...</td>\n",
       "      <td>This work is devoted to study the existence ...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Llibre', 'Jaume', ''], ['Novaes', 'Douglas ...</td>\n",
       "      <td>0.495319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15464</th>\n",
       "      <td>240592</td>\n",
       "      <td>Dual morse index estimates and application to ...</td>\n",
       "      <td>In this paper, we study the multiplicity of ...</td>\n",
       "      <td>[AP]</td>\n",
       "      <td>[['Tang', 'Shanshan', '']]</td>\n",
       "      <td>0.484760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16638</th>\n",
       "      <td>15846</td>\n",
       "      <td>The meromorphic nonintegrability of the threeb...</td>\n",
       "      <td>We study the planar threebody problem and pr...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Tsygvintsev', 'Alexei', '']]</td>\n",
       "      <td>0.475719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      original_index                                              title  \\\n",
       "6867           63325  Planar polynomial vector fields having a polyn...   \n",
       "10619         468612  Rational integrals of 2dimensional geodesic fl...   \n",
       "10096         325855  Averaging theory at any order for computing li...   \n",
       "15464         240592  Dual morse index estimates and application to ...   \n",
       "16638          15846  The meromorphic nonintegrability of the threeb...   \n",
       "\n",
       "                                                abstract     strip_cat  \\\n",
       "6867     We consider in this work planar polynomial d...      [CA, DS]   \n",
       "10619    This paper is devoted to searching for Riema...  [DS, AP, DG]   \n",
       "10096    This work is devoted to study the existence ...          [DS]   \n",
       "15464    In this paper, we study the multiplicity of ...          [AP]   \n",
       "16638    We study the planar threebody problem and pr...          [DS]   \n",
       "\n",
       "                                          authors_parsed  Cosine Similarity  \n",
       "6867   [['Garcia', 'Belen', ''], ['Giacomini', 'Hecto...           0.597346  \n",
       "10619  [['Agapov', 'Sergei', '', '1 and 2'], ['Shubin...           0.531299  \n",
       "10096  [['Llibre', 'Jaume', ''], ['Novaes', 'Douglas ...           0.495319  \n",
       "15464                         [['Tang', 'Shanshan', '']]           0.484760  \n",
       "16638                    [['Tsygvintsev', 'Alexei', '']]           0.475719  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"----------------- Doc2Vec Model (Dist. Bag of Words)-----------------\\n\")\n",
    "df_dv_bow[['original_index', 'title', 'abstract', 'strip_cat', 'authors_parsed', 'Cosine Similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "22cd9733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Doc2Vec Model (Dist. Memory)-----------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9508</th>\n",
       "      <td>315961</td>\n",
       "      <td>Planar Semiquasi Homogeneous Polynomial differ...</td>\n",
       "      <td>This paper study the planar semiquasi homoge...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Tian', 'Yuzhou', ''], ['Liang', 'Haihua', '']]</td>\n",
       "      <td>0.499888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>408265</td>\n",
       "      <td>The local period function for Hamiltonian syst...</td>\n",
       "      <td>In the first part of the paper we develop a ...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Buzzi', 'Claudio A.', ''], ['Carvalho', 'Ya...</td>\n",
       "      <td>0.476396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>63325</td>\n",
       "      <td>Planar polynomial vector fields having a polyn...</td>\n",
       "      <td>We consider in this work planar polynomial d...</td>\n",
       "      <td>[CA, DS]</td>\n",
       "      <td>[['Garcia', 'Belen', ''], ['Giacomini', 'Hecto...</td>\n",
       "      <td>0.457078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16329</th>\n",
       "      <td>379056</td>\n",
       "      <td>On the finite cyclicity of open period annuli</td>\n",
       "      <td>Let  be an open, relatively compact period a...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Gavrilov', 'Lubomir', ''], ['Novikov', 'Dmi...</td>\n",
       "      <td>0.449955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15936</th>\n",
       "      <td>329106</td>\n",
       "      <td>Bifurcation of limit cycles from a quadratic g...</td>\n",
       "      <td>In this paper, we generalize the PicardFuchs...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Yang', 'Jihua', '']]</td>\n",
       "      <td>0.447468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      original_index                                              title  \\\n",
       "9508          315961  Planar Semiquasi Homogeneous Polynomial differ...   \n",
       "4796          408265  The local period function for Hamiltonian syst...   \n",
       "6867           63325  Planar polynomial vector fields having a polyn...   \n",
       "16329         379056      On the finite cyclicity of open period annuli   \n",
       "15936         329106  Bifurcation of limit cycles from a quadratic g...   \n",
       "\n",
       "                                                abstract strip_cat  \\\n",
       "9508     This paper study the planar semiquasi homoge...      [DS]   \n",
       "4796     In the first part of the paper we develop a ...      [DS]   \n",
       "6867     We consider in this work planar polynomial d...  [CA, DS]   \n",
       "16329    Let  be an open, relatively compact period a...      [DS]   \n",
       "15936    In this paper, we generalize the PicardFuchs...      [DS]   \n",
       "\n",
       "                                          authors_parsed  Cosine Similarity  \n",
       "9508   [['Tian', 'Yuzhou', ''], ['Liang', 'Haihua', '']]           0.499888  \n",
       "4796   [['Buzzi', 'Claudio A.', ''], ['Carvalho', 'Ya...           0.476396  \n",
       "6867   [['Garcia', 'Belen', ''], ['Giacomini', 'Hecto...           0.457078  \n",
       "16329  [['Gavrilov', 'Lubomir', ''], ['Novikov', 'Dmi...           0.449955  \n",
       "15936                            [['Yang', 'Jihua', '']]           0.447468  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"----------------- Doc2Vec Model (Dist. Memory)-----------------\\n\")\n",
    "df_dv_dm[['original_index', 'title', 'abstract', 'strip_cat', 'authors_parsed', 'Cosine Similarity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffeb2c9",
   "metadata": {},
   "source": [
    "## Test the models using new user inputs\n",
    "\n",
    "Presumably, these articles are not already in the dataset, but we should double check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "389dcadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here are several lists of papers we are interested in\n",
    "ethan = ['1802.03426', '2304.14481', '2303.03190', '2210.13418',\n",
    "         '2210.12824', '2210.00661', '2007.02390', '1808.05860',\n",
    "         '2005.12732','1804.05690']\n",
    "\n",
    "jeeuhn = ['0905.0486', 'math/0006187', '2106.07444', '1402.0490', \n",
    "          '1512.08942', '1603.09235', 'math/0510265', 'math/0505056', \n",
    "          'math/0604379', '2209.02568']\n",
    "\n",
    "mike = ['2207.13571','2207.13498','2211.09644','2001.10647',\n",
    "        '2103.08093','2207.08245', '2207.01677','2205.08744',\n",
    "        '2008.04406','1912.09845']\n",
    "\n",
    "jenia = ['2010.14967', '1307.0493', 'quant-ph/0604014', '2201.05140', \n",
    "         '1111.1877', 'quant-ph/9912054', '1611.08286', '1507.02858', \n",
    "         'math-ph/0107001','1511.01241', 'math-ph/9904020', '2211.15336', \n",
    "         '2212.03719']\n",
    "jenia = jenia[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a4bb91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words can be accessed like so\n",
    "# print(stopwords.words('english'))\n",
    "\n",
    "## Tokenize the abstract by splitting on whitespaces\n",
    "## and get rid of the occasional empty string.\n",
    "def clear_empty(clean_string):\n",
    "    return [word for word in clean_string.split(\" \") if word != '']\n",
    "\n",
    "def remove_stop(tokens):\n",
    "    return [token for token in tokens if token not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2a8a1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_data(paper_ids_list):\n",
    "    ## Create the dataframe to store the user's input papers\n",
    "    df_user = pd.DataFrame(columns=['id','entry_id', 'title', 'authors','abstract'])\n",
    "    \n",
    "    list_urls = []\n",
    "    list_titles = []\n",
    "    list_authors = []\n",
    "    list_abstracts = []\n",
    "\n",
    "\n",
    "    for item in paper_ids_list:\n",
    "        paper = next(arxiv.Search(id_list=[item]).results())\n",
    "        list_titles.append(paper.title)\n",
    "        list_authors.append(paper.authors)\n",
    "        list_abstracts.append(paper.summary)\n",
    "        list_urls.append(paper.entry_id)\n",
    "    \n",
    "    df_user['id'] = paper_ids_list\n",
    "    df_user['entry_id'] = list_urls\n",
    "    df_user['title'] = list_titles\n",
    "    df_user['authors'] = list_authors\n",
    "    df_user['abstract'] = list_abstracts\n",
    "    \n",
    "    ## Clean the user's data\n",
    "    df_user['abstract_clean'] = df_user['abstract'].apply(clean_data)\n",
    "    df_user['abstract_tokenized'] = df_user['abstract_clean'].apply(nltk.word_tokenize)\n",
    "    df_user['abstract_tokenized'] = df_user['abstract_clean'].apply(clear_empty)\n",
    "    df_user['abstract_tokenized'] = df_user['abstract_tokenized'].apply(remove_stop)\n",
    "    \n",
    "    return df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076be516",
   "metadata": {},
   "source": [
    "### Ethan's Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7bbb0619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract_clean</th>\n",
       "      <th>abstract_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1802.03426</td>\n",
       "      <td>http://arxiv.org/abs/1802.03426v3</td>\n",
       "      <td>UMAP: Uniform Manifold Approximation and Proje...</td>\n",
       "      <td>[Leland McInnes, John Healy, James Melville]</td>\n",
       "      <td>UMAP (Uniform Manifold Approximation and Proje...</td>\n",
       "      <td>umap uniform manifold approximation and projec...</td>\n",
       "      <td>[umap, uniform, manifold, approximation, proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2304.14481</td>\n",
       "      <td>http://arxiv.org/abs/2304.14481v1</td>\n",
       "      <td>Endperiodic maps, splitting sequences, and bra...</td>\n",
       "      <td>[Michael P. Landry, Chi Cheuk Tsang]</td>\n",
       "      <td>We strengthen the unpublished theorem of Gabai...</td>\n",
       "      <td>we strengthen the unpublished theorem of gabai...</td>\n",
       "      <td>[strengthen, unpublished, theorem, gabai, mosh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2303.03190</td>\n",
       "      <td>http://arxiv.org/abs/2303.03190v1</td>\n",
       "      <td>Train track combinatorics and cluster algebras</td>\n",
       "      <td>[Shunsuke Kano]</td>\n",
       "      <td>The concepts of train track was introduced by ...</td>\n",
       "      <td>the concepts of train track was introduced by ...</td>\n",
       "      <td>[concepts, train, track, introduced, w, p, thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2210.13418</td>\n",
       "      <td>http://arxiv.org/abs/2210.13418v2</td>\n",
       "      <td>Standardly embedded train tracks and pseudo-An...</td>\n",
       "      <td>[Eriko Hironaka, Chi Cheuk Tsang]</td>\n",
       "      <td>We show that given a fully-punctured pseudo-An...</td>\n",
       "      <td>we show that given a fully punctured pseudo an...</td>\n",
       "      <td>[show, given, fully, punctured, pseudo, anosov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2210.12824</td>\n",
       "      <td>http://arxiv.org/abs/2210.12824v2</td>\n",
       "      <td>Class number for pseudo-Anosovs</td>\n",
       "      <td>[François Dahmani, Mahan Mj]</td>\n",
       "      <td>Given two automorphisms of a group $G$, one is...</td>\n",
       "      <td>given two automorphisms of a group  one is int...</td>\n",
       "      <td>[given, two, automorphisms, group, one, intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2210.00661</td>\n",
       "      <td>http://arxiv.org/abs/2210.00661v1</td>\n",
       "      <td>Braids, entropies and fibered 2-fold branched ...</td>\n",
       "      <td>[Susumu Hirose, Eiko Kin]</td>\n",
       "      <td>It is proved by Sakuma and Brooks that any clo...</td>\n",
       "      <td>it is proved by sakuma and brooks that any clo...</td>\n",
       "      <td>[proved, sakuma, brooks, closed, orientable, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007.02390</td>\n",
       "      <td>http://arxiv.org/abs/2007.02390v1</td>\n",
       "      <td>The (homological) persistence of gerrymandering</td>\n",
       "      <td>[Moon Duchin, Tom Needham, Thomas Weighill]</td>\n",
       "      <td>We apply persistent homology, the dominant too...</td>\n",
       "      <td>we apply persistent homology the dominant tool...</td>\n",
       "      <td>[apply, persistent, homology, dominant, tool, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1808.05860</td>\n",
       "      <td>http://arxiv.org/abs/1808.05860v1</td>\n",
       "      <td>Discrete geometry for electoral geography</td>\n",
       "      <td>[Moon Duchin, Bridget Eileen Tenner]</td>\n",
       "      <td>We discuss the \"compactness,\" or shape analysi...</td>\n",
       "      <td>we discuss the compactness or shape analysis o...</td>\n",
       "      <td>[discuss, compactness, shape, analysis, electo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2005.12732</td>\n",
       "      <td>http://arxiv.org/abs/2005.12732v1</td>\n",
       "      <td>Mathematics of Nested Districts: The Case of A...</td>\n",
       "      <td>[Sophia Caldera, Daryl DeFord, Moon Duchin, Sa...</td>\n",
       "      <td>In eight states, a \"nesting rule\" requires tha...</td>\n",
       "      <td>in eight states a nesting rule requires that e...</td>\n",
       "      <td>[eight, states, nesting, rule, requires, state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1804.05690</td>\n",
       "      <td>http://arxiv.org/abs/1804.05690v4</td>\n",
       "      <td>You can hear the shape of a billiard table: Sy...</td>\n",
       "      <td>[Moon Duchin, Viveka Erlandsson, Christopher J...</td>\n",
       "      <td>We give a complete characterization of the rel...</td>\n",
       "      <td>we give a complete characterization of the rel...</td>\n",
       "      <td>[give, complete, characterization, relationshi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                           entry_id  \\\n",
       "0  1802.03426  http://arxiv.org/abs/1802.03426v3   \n",
       "1  2304.14481  http://arxiv.org/abs/2304.14481v1   \n",
       "2  2303.03190  http://arxiv.org/abs/2303.03190v1   \n",
       "3  2210.13418  http://arxiv.org/abs/2210.13418v2   \n",
       "4  2210.12824  http://arxiv.org/abs/2210.12824v2   \n",
       "5  2210.00661  http://arxiv.org/abs/2210.00661v1   \n",
       "6  2007.02390  http://arxiv.org/abs/2007.02390v1   \n",
       "7  1808.05860  http://arxiv.org/abs/1808.05860v1   \n",
       "8  2005.12732  http://arxiv.org/abs/2005.12732v1   \n",
       "9  1804.05690  http://arxiv.org/abs/1804.05690v4   \n",
       "\n",
       "                                               title  \\\n",
       "0  UMAP: Uniform Manifold Approximation and Proje...   \n",
       "1  Endperiodic maps, splitting sequences, and bra...   \n",
       "2     Train track combinatorics and cluster algebras   \n",
       "3  Standardly embedded train tracks and pseudo-An...   \n",
       "4                    Class number for pseudo-Anosovs   \n",
       "5  Braids, entropies and fibered 2-fold branched ...   \n",
       "6    The (homological) persistence of gerrymandering   \n",
       "7          Discrete geometry for electoral geography   \n",
       "8  Mathematics of Nested Districts: The Case of A...   \n",
       "9  You can hear the shape of a billiard table: Sy...   \n",
       "\n",
       "                                             authors  \\\n",
       "0       [Leland McInnes, John Healy, James Melville]   \n",
       "1               [Michael P. Landry, Chi Cheuk Tsang]   \n",
       "2                                    [Shunsuke Kano]   \n",
       "3                  [Eriko Hironaka, Chi Cheuk Tsang]   \n",
       "4                       [François Dahmani, Mahan Mj]   \n",
       "5                          [Susumu Hirose, Eiko Kin]   \n",
       "6        [Moon Duchin, Tom Needham, Thomas Weighill]   \n",
       "7               [Moon Duchin, Bridget Eileen Tenner]   \n",
       "8  [Sophia Caldera, Daryl DeFord, Moon Duchin, Sa...   \n",
       "9  [Moon Duchin, Viveka Erlandsson, Christopher J...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  UMAP (Uniform Manifold Approximation and Proje...   \n",
       "1  We strengthen the unpublished theorem of Gabai...   \n",
       "2  The concepts of train track was introduced by ...   \n",
       "3  We show that given a fully-punctured pseudo-An...   \n",
       "4  Given two automorphisms of a group $G$, one is...   \n",
       "5  It is proved by Sakuma and Brooks that any clo...   \n",
       "6  We apply persistent homology, the dominant too...   \n",
       "7  We discuss the \"compactness,\" or shape analysi...   \n",
       "8  In eight states, a \"nesting rule\" requires tha...   \n",
       "9  We give a complete characterization of the rel...   \n",
       "\n",
       "                                      abstract_clean  \\\n",
       "0  umap uniform manifold approximation and projec...   \n",
       "1  we strengthen the unpublished theorem of gabai...   \n",
       "2  the concepts of train track was introduced by ...   \n",
       "3  we show that given a fully punctured pseudo an...   \n",
       "4  given two automorphisms of a group  one is int...   \n",
       "5  it is proved by sakuma and brooks that any clo...   \n",
       "6  we apply persistent homology the dominant tool...   \n",
       "7  we discuss the compactness or shape analysis o...   \n",
       "8  in eight states a nesting rule requires that e...   \n",
       "9  we give a complete characterization of the rel...   \n",
       "\n",
       "                                  abstract_tokenized  \n",
       "0  [umap, uniform, manifold, approximation, proje...  \n",
       "1  [strengthen, unpublished, theorem, gabai, mosh...  \n",
       "2  [concepts, train, track, introduced, w, p, thu...  \n",
       "3  [show, given, fully, punctured, pseudo, anosov...  \n",
       "4  [given, two, automorphisms, group, one, intere...  \n",
       "5  [proved, sakuma, brooks, closed, orientable, m...  \n",
       "6  [apply, persistent, homology, dominant, tool, ...  \n",
       "7  [discuss, compactness, shape, analysis, electo...  \n",
       "8  [eight, states, nesting, rule, requires, state...  \n",
       "9  [give, complete, characterization, relationshi...  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ethan = user_data(ethan)\n",
    "df_ethan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "72e13288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Word2Vec\n",
      "Execution time: 5.081173849105835 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "## Using the pretrained Word2Vec\n",
    "df_rec_wv, df_ethan_new_wv = n_recommendations(w2v_model, df, df_ethan[0:2], 10)\n",
    "\n",
    "end = time.time()\n",
    "res = (end - start)/60\n",
    "print('Execution time:', res, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "71374b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Word2Vec Model ---------------------\n",
      "\n",
      "The top 10 articles most similar to the articles: \n",
      "\n",
      "\n",
      "1 . UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction\n",
      "2 . Endperiodic maps, splitting sequences, and branched surfaces\n",
      "\n",
      "#############################################################\n",
      "\n",
      "1 . ( 7133 ) Area minimizing hypersurfaces modulo : a geometric freeboundary   problem \n",
      " [ Cosine Similarity= 0.888 ]\n",
      "\n",
      "\n",
      "   We consider area minimizing dimensional currents  in complete  Riemannian manifolds  of dimension . For odd moduli we prove that, away from a closed rectifiable set of codimension , the current in question is, locally, the union of finitely many smooth minimal hypersurfaces coming together at a common  boundary of dimension , and the result is optimal. For even  such structure holds in a neighborhood of any point where at least one tangent cone has dimensional spine. These structural results are indeed the byproduct of a theorem that proves (for any modulus) uniqueness and decay towards such tangent cones. The underlying strategy of the proof is inspired by the techniques developed by Leon Simon in \"Cylindrical tangent cones and the singular set of minimal submanifolds\" (J. Diff. Geom. 1993) in a class of multiplicity one stationary varifolds. The major difficulty in our setting is produced by the fact that the cones and surfaces under investigation have arbitrary multiplicities ranging from  to . \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "2 . ( 11851 ) Complete periodicity of Prym eigenforms \n",
      " [ Cosine Similarity= 0.862 ]\n",
      "\n",
      "\n",
      "   This paper deals with Prym eigenforms which are introduced previously by McMullen. We prove several results on the directional flow on those surfaces, related to complete periodicity (introduced by Calta). More precisely we show that any homological direction is algebraically periodic, and any direction of a regular closed geodesic is a completely periodic direction. As a consequence we draw that the limit set of the Veech group of every Prym eigenform in some Prym loci of genus 3,4, and 5 is either empty, one point, or the full circle at infinity. We also construct new examples of translation surfaces satisfying the topological Veech dichotomy. As a corollary we obtain new translation surfaces whose Veech group is infinitely generated and of the first kind. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "3 . ( 16290 ) Geometry of foliations and flows I: Almost transverse pseudoAnosov   flows and asymptotic behavior of foliations \n",
      " [ Cosine Similarity= 0.859 ]\n",
      "\n",
      "\n",
      "   Let F be a foliation in a closed 3manifold with negatively curved fundamental group and suppose that F is almost transverse to a quasigeodesic pseudoAnosov flow. We show that the leaves of the foliation in the universal cover extend continuously to the sphere at infinity, hence the limit sets are continuous images of the circle. One important corollary is that if F is a Reebless finite depth foliation in a hyperbolic manifold, then it has the continuous extension property. Such finite depth foliations exist whenever the second Betti number is non zero. The result also applies to other classes of foliations, including a large class of foliations where all leaves are dense and infinitely many examples with one sided branching. One key tool is a detailed understanding of asymptotic properties of almost pseudoAnosov singular 1dimensional foliations in the leaves of F lifted to the universal cover. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "4 . ( 761 ) Rectifiability of Singular Sets in Noncollapsed Spaces with Ricci   Curvature bounded below \n",
      " [ Cosine Similarity= 0.858 ]\n",
      "\n",
      "\n",
      "   This paper is concerned with the structure of GromovHausdorff limit spaces  of Riemannian manifolds satisfying a uniform lower Ricci curvature bound  as well as the noncollapsing assumption . In such cases, there is a filtration of the singular set, , where x; equivalently no tangent cone splits off a Euclidean factor  isometrically. Moreover, by , . However, little else has been understood about the structure of the singular set .   Our first result for such limit spaces  states that  is rectifiable. In fact, we will show that for a.e. , {\\it every} tangent cone  at  is symmetric i.e. that  where  might depend on the particular . We use this to show that there exists , and a rectifible set , with finite dimensional Hausdorff measure , such that  is biH\\\"older equivalent to a smooth riemannian manifold. This improves the regularity results of . Additionally, we will see that tangent cones are unique of a subset of Hausdorff  dimensional measure zero.   Our analysis is based on several new ideas, including a sharp conesplitting theorem and a geometric transformation theorem, which will allow us to control the degeneration of harmonic functions on these neck regions. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "5 . ( 11576 ) The Casimir effect from the point of view of algebraic quantum field   theory \n",
      " [ Cosine Similarity= 0.856 ]\n",
      "\n",
      "\n",
      "   We consider a region of Minkowski spacetime bounded either by one or by two parallel, infinitely extended plates orthogonal to a spatial direction and a real KleinGordon field satisfying Dirichlet boundary conditions. We quantize these two systems within the algebraic approach to quantum field theory using the socalled functional formalism. As a first step we construct a suitable unital *algebra of observables whose generating functionals are characterized by a labelling space which is at the same time optimal and separating and fulfils the Flocality property. Subsequently we give a definition for these systems of Hadamard states and we investigate explicit examples. In the case of a single plate, it turns out that one can build algebraic states via a pullback of those on the whole Minkowski spacetime, moreover inheriting from them the Hadamard property. When we consider instead two plates, algebraic states can be put in correspondence with those on flat spacetime via the socalled method of images, which we translate to the algebraic setting. For a massless scalar field we show that this procedure works perfectly for a large class of quasifree states including the Poincar\\'e vacuum and KMS states. Eventually Wick polynomials are introduced. Contrary to the Minkowski case, the extended algebras, built in globally hyperbolic subregions can be collected in a global counterpart only after a suitable deformation which is expressed locally in terms of a *isomorphism. As a last step, we construct explicitly the twopoint function and the regularized energy density, showing, moreover, that the outcome is consistent with the standard results of the Casimir effect. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "6 . ( 10020 ) Laminations and 2filling rays on infinite type surfaces \n",
      " [ Cosine Similarity= 0.856 ]\n",
      "\n",
      "\n",
      "   The loop graph of an infinite type surface is an infinite diameter hyperbolic graph first studied in detail by Juliette Bavard. An important open problem in the study of infinite type surfaces is to describe the boundary of the loop graph as a space of geodesic laminations. We approach this problem by constructing the first examples of 2filling rays on infinite type surfaces. Such rays accumulate onto geodesic laminations which are in some sense filling, but without strong enough properties to correspond to points in the boundary of the loop graph. We give multiple constructions using both a handson combinatorial approach and an approach using train tracks and automorphisms of flat surfaces. In addition, our approaches are sufficiently robust to describe all 2filling rays with certain other basic properties as well as to produce uncountably many distinct mapping class group orbits. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "7 . ( 3947 ) Counting hyperbolic multigeodesics with respect to the lengths of   individual components \n",
      " [ Cosine Similarity= 0.854 ]\n",
      "\n",
      "\n",
      "   Given a connected, oriented, complete, finite area hyperbolic surface  of genus  with  punctures, Mirzakhani showed that the number of multigeodesics on  of total hyperbolic length  in the mapping class group orbit of a given simple or filling closed multicurve is asymptotic as  to a polynomial in  of degree . We establish asymptotics of the same kind for countings of multigeodesics in mapping class group orbits of simple or filling closed multicurves that keep track of the hyperbolic lengths of individual components, proving and generalizing a conjecture of Wolpert. In the simple case we consider more precise countings that also keep track of the class of the multigeodesics in the space of projective measured geodesic laminations. We provide a unified geometric and topological description of the leading terms of the asymptotics of all the countings considered. Our proofs combine techniques and results from several papers of Mirzakhani as well as ideas introduced by Margulis in his thesis. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "8 . ( 11525 ) Entropy decay in the SwendsenWang dynamics on  \n",
      " [ Cosine Similarity= 0.853 ]\n",
      "\n",
      "\n",
      "   We study the mixing time of the SwendsenWang dynamics for the ferromagnetic Ising and Potts models on the integer lattice . This dynamics is a widely used Markov chain that has largely resisted sharp analysis because it is nonlocal, i.e., it changes the entire configuration in one step. We prove that, whenever Strong Spatial Mixing (SSM) holds, the mixing time on any vertex cube in  is , and we prove this is tight by establishing a matching lower bound on the mixing time. The previous best known bound was . SSM is a standard condition corresponding to exponential decay of correlations with distance between spins on the lattice and is known to hold in  dimensions throughout the hightemperature (single phase) region. Our result follows from a Modified LogSobolev Inequality, which expresses the fact that the dynamics contracts relative entropy at a constant rate at each step. The proof of this fact utilizes a new factorization of the entropy in the joint probability space over spins and edges that underlies the SwendsenWang dynamics, which extends to general bipartite graphs of bounded degree. This factorization leads to several additional results, including mixing time bounds for a number of natural local and nonlocal Markov chains on the joint space, as well as for the standard randomcluster dynamics. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "9 . ( 3884 ) Obstruction bundles over moduli spaces with boundary and the action   filtration in symplectic field theory \n",
      " [ Cosine Similarity= 0.853 ]\n",
      "\n",
      "\n",
      "   Branched covers of orbit cylinders are the basic examples of holomorphic curves studied in symplectic field theory. Since all curves with Fredholm index one can never be regular for any choice of cylindrical almost complex structure, we generalize the obstruction bundle technique of Taubes for determining multiple cover contributions from GromovWitten theory to the case of moduli spaces with boundary. Our result proves that the differential in rational symplectic field theory and contact homology is strictly decreasing with respect to the natural action filtration. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "10 . ( 4727 ) Mean Curvature Flow of Spacelike Graphs \n",
      " [ Cosine Similarity= 0.853 ]\n",
      "\n",
      "\n",
      "   We prove the mean curvature flow of a spacelike graph in  of a map  from a closed Riemannian manifold  with  to a complete Riemannian manifold  with bounded curvature tensor and derivatives, and with sectional curvatures satisfying , remains a spacelike graph, exists for all time, and converges to a slice at infinity. We also show, with no need of the assumption , that if , or if  and ,  constant, any map  is trivially homotopic provided  where , in case , and  in case . This largely extends some known results for  constant and  compact, obtained using the Riemannian structure of , and also shows how regularity theory on the mean curvature flow is simpler and more natural in pseudoRiemannian setting then in the Riemannian one. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------- Word2Vec Model ---------------------\\n\")\n",
    "display_results(df_rec_wv, df_ethan_new_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "328f4caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Doc2Vec\n",
      "Execution time: 5.084524818261465 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "## Using Doc2Vec with Distributed Bag of Words\n",
    "df_rec_d2v_bow, df_ethan_new_bow = n_recommendations(d2v_model_bow, df, df_ethan[0:2], 10)\n",
    "\n",
    "end = time.time()\n",
    "res = (end - start)/60\n",
    "print('Execution time:',res, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2b8b03c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Doc2Vec Model (Dist. Bag of Words)-----------------\n",
      "\n",
      "The top 10 articles most similar to the articles: \n",
      "\n",
      "\n",
      "1 . UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction\n",
      "2 . Endperiodic maps, splitting sequences, and branched surfaces\n",
      "\n",
      "#############################################################\n",
      "\n",
      "1 . ( 16855 ) A factorization theorem for harmonic maps \n",
      " [ Cosine Similarity= 0.319 ]\n",
      "\n",
      "\n",
      "   Let  be a harmonic map from a Riemann surface to a Riemannian manifold. We prove that if there is a holomorphic diffeomorphism  between open subsets of the surface such that , then  factors through a holomorphic map onto another Riemann surface. If such  is antiholomorphic, we obtain an analogous statement. For minimal maps, this result is well known and is a consequence of the theory of branched immersions of surfaces due to GulliverOssermanRoyden. Our proof relies on various geometric properties of the Hopf differential. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "2 . ( 12427 ) Minimal entropy and collapsing with curvature bounded from below \n",
      " [ Cosine Similarity= 0.313 ]\n",
      "\n",
      "\n",
      "   We show that if a closed manifold M admits an Fstructure (possibly of rank 0) then its minimal entropy vanishes. In particular, this is the case if M admits a nontrivial circle action. As a corollary we obtain that the simplicial volume of a colsed manifold admitting an Fstructure is zero. We also show that if M admits an Fstructure then it collapses with curvature bounded from below. This is turn implies that M collapses with bounded scalar curvature or, equivalently, its Yamabe invariant is nonnegative. We show that Fstructures of rank zero appear rather frequently:every compact complex elliptic surface admits one as well as any simply connected 5manifold. We use these results to study the minimal entropy problem. We show the following two theorems: suppose M is obtained by taking connected sums of copies of CP^2 (with any orintation), S^2 \\times S^2 and the K3 surface. Then M has zero minimal entropy. Moreover, M admits a metric with zero topological entropy if and only if M is diffeomorphic to S^4, CP^2, S^2 \\times S^2, CP^2#CP^2 or CP^2#(CP^2). Finally, suppose that M is a closed simply connected 5manifold. Than M has zero minimal entropy. Moreover, M admits a metric with zero topological entropy if and only if M is diffeomorphic to S^5, S^3 \\times S^2, the nontrivial S^3bundle over S^2 or the Wu manifold SU(3)/SO(3). \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "3 . ( 278 ) Compact Complex Surfaces and Constant Scalar Curvature K\\\"ahler Metrics \n",
      " [ Cosine Similarity= 0.313 ]\n",
      "\n",
      "\n",
      "   In this article, I prove the following statement: Every compact complex surface with even first Betti number is deformation equivalent to one which admits an extremal K\\\"ahler metric. In fact, this extremal K\\\"ahler metric can even be taken to have constant scalar curvature in all but two cases: the deformation equivalence classes of the blowup of  at one or two points. The explicit construction of compact complex surfaces with constant scalar curvature K\\\"ahler metrics in different deformation equivalence classes is given. The main tool repeatedly applied here is the gluing theorem of C. Arezzo and F. Pacard which states that the blowup/resolution of a compact manifold/orbifold of discrete type, which admits cscK metrics, still admits cscK metrics. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "4 . ( 3333 ) Brownian motion on stationary random manifolds \n",
      " [ Cosine Similarity= 0.309 ]\n",
      "\n",
      "\n",
      "   We introduce the notion of a stationary random manifold and develop the basic entropy theory for it. Examples include manifolds admitting a compact quotient under isometries and generic leaves of a compact foliation. We prove that the entropy of an ergodic stationary random manifold is zero if and only if the manifold satisfies the Liouville property almost surely, and is positive if and only if it admits an infinite dimensional space of bounded harmonic functions almost surely. Upper and lower bounds for the entropy are provided in terms of the linear drift of Brownian motion and average volume growth of the manifold. Other almost sure properties of these random manifolds are also studied. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "5 . ( 6503 ) Existence of periodic orbits for sectional Anosov flows \n",
      " [ Cosine Similarity= 0.308 ]\n",
      "\n",
      "\n",
      "   We prove that every sectional Anosov flow (or, equivalently, every sectionalhyperbolic attracting set of a flow) on a compact manifold has a periodic orbit. This extends the previous threedimensional result obtained in . \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "6 . ( 8277 ) The group of isometries of a locally compact metric space with one end \n",
      " [ Cosine Similarity= 0.301 ]\n",
      "\n",
      "\n",
      "   In this note we study the dynamics of the natural evaluation action of the group of isometries  of a locally compact metric space  with one end. Using the notion of pseudocomponents introduced by S. Gao and A. S. Kechris we show that  has only finitely many pseudocomponents of which exactly one is not compact and  acts properly on. The complement of the noncompact component is a compact subset of  and  may fail to act properly on it. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "7 . ( 19524 ) Upper bounds for the function solution of the homogenuous 2D Boltzmann   equation with hard potential \n",
      " [ Cosine Similarity= 0.296 ]\n",
      "\n",
      "\n",
      "   We deal with  the solution of the homogeneous  Boltzmannequation without cutoff. The initial condition  may be anyprobability distribution (except a Dirac mass). However, for sufficiently hardpotentials, the semigroup has a regularization property (see ): for every  The aim of this paper is to give upperbounds for  the most significant one being of type  for some  \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "8 . ( 12155 ) On the existence of supporting broken book decompositions for contact   forms in dimension 3 \n",
      " [ Cosine Similarity= 0.295 ]\n",
      "\n",
      "\n",
      "   We prove that in dimension 3 every nondegenerate contact form is carried by a broken book decomposition. As an application we get that if M is a closed irreducible oriented 3manifold that is not a graph manifold, for example a hyperbolic manifold, then every nondegenerate Reeb vector field on M has positive topological entropy. Moreover, we obtain that on a closed 3manifold, every nondegenerate Reeb vector field has either two or infinitely many periodic orbits, and two periodic orbits are possible only on the sphere or on a lens space. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "9 . ( 11959 ) Locally conformally Kaehler metrics on Kato surfaces \n",
      " [ Cosine Similarity= 0.294 ]\n",
      "\n",
      "\n",
      "   We show that every Kato surface (or surface with a global spherical shell) admits a locally conformally Kaehler metric. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "10 . ( 5281 ) Almostformality and deformations of representations of the fundamental   groups of Sasakian manifolds \n",
      " [ Cosine Similarity= 0.291 ]\n",
      "\n",
      "\n",
      "   For a dimensional compact Sasakian manifold, if , we prove that the analytic germ of the variety of representations of the fundamental group at every semisimple representation is quadratic. To prove this result, we prove the almostformality of de Rham complex of a Sasakian manifold with values in a semisimple flat vector bundle. By the almostformality, we also prove the vanishing theorem on the cup product of the cohomology of semisimple flat vector bundles over a compact Sasakian manifold. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"----------------- Doc2Vec Model (Dist. Bag of Words)-----------------\\n\")\n",
    "display_results(df_rec_d2v_bow, df_ethan_new_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "29c4ea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Doc2Vec\n",
      "Execution time: 5.3633530855178835 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "## Using Doc2Vec with Distributed Memory\n",
    "df_rec_d2v_dm, df_ethan_new_dm = n_recommendations(d2v_model_dm, df, df_ethan[0:2], 10)\n",
    "\n",
    "end = time.time()\n",
    "res = (end - start)/60\n",
    "print('Execution time:',res, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "128dcbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Doc2Vec Model (Dist. Memory)-----------------\n",
      "\n",
      "The top 10 articles most similar to the articles: \n",
      "\n",
      "\n",
      "1 . UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction\n",
      "2 . Endperiodic maps, splitting sequences, and branched surfaces\n",
      "\n",
      "#############################################################\n",
      "\n",
      "1 . ( 16290 ) Geometry of foliations and flows I: Almost transverse pseudoAnosov   flows and asymptotic behavior of foliations \n",
      " [ Cosine Similarity= 0.887 ]\n",
      "\n",
      "\n",
      "   Let F be a foliation in a closed 3manifold with negatively curved fundamental group and suppose that F is almost transverse to a quasigeodesic pseudoAnosov flow. We show that the leaves of the foliation in the universal cover extend continuously to the sphere at infinity, hence the limit sets are continuous images of the circle. One important corollary is that if F is a Reebless finite depth foliation in a hyperbolic manifold, then it has the continuous extension property. Such finite depth foliations exist whenever the second Betti number is non zero. The result also applies to other classes of foliations, including a large class of foliations where all leaves are dense and infinitely many examples with one sided branching. One key tool is a detailed understanding of asymptotic properties of almost pseudoAnosov singular 1dimensional foliations in the leaves of F lifted to the universal cover. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "2 . ( 16179 ) Geometry of noncompact minimal and marginally outertrapped surfaces in   asymptotically flat manifolds \n",
      " [ Cosine Similarity= 0.886 ]\n",
      "\n",
      "\n",
      "   In this article we extend several foundational results of the theory of complete minimal surfaces of finite index in the Euclidean space to minimal surfaces in asymptotically flat manifolds and, more generally, to marginally outertrapped surfaces in initial data sets of General Relativity. We show that if an asymptotically flat 3manifold (M,g) of nonnegative scalar curvature contains a noncompact, properly embedded minimal surface which is stable and has quadratic area growth, then it is isometric to the flat R^{3}. This implies, for instance, that in presence of a positive ADM mass any sequence of solutions to the Plateau problem with diverging boundaries can never have uniform height bounds, even at a single point. The proof of this theorem is based on a characterization of finite index minimal surfaces, on classical infinitesimal rigidity results by FischerColbrie and Schoen and on the positive mass theorem by SchoenYau. More specifically, we also show that a complete minimal surface of finite index inside an asymptotically flat 3manifold has finitely many ends and each of these is a graph of a function that has a suitable expansion at infinity, in analogy with a classical result by Schoen for Euclidean spaces. In addition, we prove that a noncompact stable MOTS in an initial data set (M,g,k) is conformally diffeomorphic to either the plane C or to the cylinder A and in the latter case infinitesimal rigidity holds. If the data have harmonic asymptotics, the former case is also proven to be globally rigid in the sense that the presence of a stable MOTS forces an isometric embedding of (M,g,k) in the Minkowski spacetime (\\mathbb{M},\\eta) as a spacelike slice. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "3 . ( 15960 ) Characteristic foliations on maximally real submanifolds of C^n and   envelopes of holomorphy \n",
      " [ Cosine Similarity= 0.883 ]\n",
      "\n",
      "\n",
      "   Let S be an arbitrary real surface, with or without boundary, contained in a hypersurface M of the complex euclidean space \\C^2, with S and M of class C^{2, a}, where 0 < a < 1. If M is globally minimal, if S is totally real except at finitely many complex tangencies which are hyperbolic in the sense of E. Bishop and if the union of separatrices is a tree of curves without cycles, we show that every compact K of S is CR, W and L^premovable (Theorem~1.3). We treat this seemingly global problem by means of purely local techniques, namely by means of families of small analytic discs partially attached to maximally real submanifolds of C^n and by means of a thorough study of the relative disposition of the characteristic foliation with respect to the track on M of a certain halfwedge attached to M. This localization procedure enables us to answer an open problem raised by B. J\\\"oricke: under a certain nontransversality condition with respect to the characteristic foliation, we show that every closed subset C of a C^{2,a}smooth maximally real submanifold M^1 of a (n1)codimensional generic C^{2,a}smooth submanifold of \\C^n is CR, W and L^premovable (Theorem~1.2'). The known removability results in CR dimension at least two appear to be logical consequences of Theorem~1.2'. The main proof (65p.) is written directly in arbitrary codimension. Finally, we produce an example of a nonremovable 2torus contained in a maximally real 3dimensional maximally real submanifold, showing that the nontransversality condition is optimal for universal removability. Numerous figures are included to help readers who are not insiders of higher codimensional geometry. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "4 . ( 3034 ) Minimal graphs over Riemannian surfaces and harmonic diffeomorphisms \n",
      " [ Cosine Similarity= 0.882 ]\n",
      "\n",
      "\n",
      "   We construct a parabolic entire minimal graph  over a finite topology complete Riemannian surface  of curvature  and infinite area (thus of nonparabolic conformal type). The vertical projection of this graph yields a harmonic diffeomorphism from  onto . The proof uses the theory of divergence lines to construct minimal graphs.   We also generalize a theorem of R. Schoen. Let  and  be two complete metrics on a orientable surface  with compact boundary and suppose  for some  and all . If there is a harmonic diffeomorphism from  to , then  is parabolic. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "5 . ( 18690 ) Isometric immersions into 3dimensional homogeneous manifolds \n",
      " [ Cosine Similarity= 0.881 ]\n",
      "\n",
      "\n",
      "   We give a necessary and sufficient condition for a 2dimensional Riemannian manifold to be locally isometrically immersed into a 3dimensional homogeneous manifold with a 4dimensional isometry group. The condition is expressed in terms of the metric, the second fundamental form, and data arising from an ambient Killing field. This class of 3manifolds includes in particular the Berger spheres, the Heisenberg space Nil(3), the universal cover of the Lie group PSL(2,R) and the product spaces S^2 x R and H^2 x R. We give some applications to constant mean curvature (CMC) surfaces in these manifolds; in particular we prove the existence of a generalized Lawson correspondence, i.e., a local isometric correspondence between CMC surfaces in homogeneous 3manifolds. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "6 . ( 18175 ) Closed surface bundles of least volume \n",
      " [ Cosine Similarity= 0.881 ]\n",
      "\n",
      "\n",
      "   Since the set of volumes of hyperbolic 3manifolds is well ordered, for each fixed g there is a genusg surface bundle over the circle of minimal volume. Here, we introduce an explicit family of genusg bundles which we conjecture are the unique such manifolds of minimal volume. Conditional on a very plausible assumption, we prove that this is indeed the case when g is large. The proof combines a soft geometric limit argument with a detailed NeumannZagier asymptotic formula for the volumes of Dehn fillings.   Our examples are all Dehn fillings on the sibling of the Whitehead manifold, and we also analyze the dilatations of all closed surface bundles obtained in this way, identifying those with minimal dilatation. This gives new families of pseudoAnosovs with low dilatation, including a genus 7 example which minimizes dilatation among all those with orientable invariant foliations. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "7 . ( 5662 ) Holomorphic Legendrian curves \n",
      " [ Cosine Similarity= 0.881 ]\n",
      "\n",
      "\n",
      "   In this paper we study holomorphic Legendrian curves in the standard holomorphic contact structure on  for any . We provide several approximation and desingularization results which enable us to prove general existence theorems, settling some of the open problems in the subject. In particular, we show that every open Riemann surface  admits a proper holomorphic Legendrian embedding , and we prove that for every compact bordered Riemann surface  there exists a topological embedding  whose restriction to the interior is a complete holomorphic Legendrian embedding . As a consequence, we infer that every complex contact manifold  carries relatively compact holomorphic Legendrian curves, normalized by any given bordered Riemann surface, which are complete with respect to any Riemannian metric on . \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "8 . ( 5120 ) Areastationary surfaces in the Heisenberg group H^1 \n",
      " [ Cosine Similarity= 0.88 ]\n",
      "\n",
      "\n",
      "   We use variational arguments to introduce a notion of mean curvature for surfaces in the Heisenberg group H^1 endowed with its CarnotCarath\\'eodory distance. By analyzing the first variation of area, we characterize C^2 stationary surfaces for the area as those with mean curvature zero (or constant if a volumepreserving condition is assumed) and such that the characteristic curves meet orthogonally the singular curves. Moreover, a Minkowski type formula relating the area, the mean curvature, and the volume is obtained for volumepreserving areastationary surfaces enclosing a given region.   As a consequence of the characterization of areastationary surfaces, we refine previous Bernstein type theorems in order to describe entire areastationary graphs over the xyplane in H^1. A calibration argument shows that these graphs are globally areaminimizing.   Finally, by using the known description of the singular set, the characterization of areastationary surfaces, and the ruling property of constant mean curvature surfaces, we prove our main results where we classify volumepreserving areastationary surfaces in H^1 with nonempty singular set. In particular, we deduce the following counterpart to Alexandrov uniqueness theorem in Euclidean space: any compact, connected, C^2 surface in H^1 areastationary under a volume constraint must be congruent with a rotationally symmetric sphere obtained as the union of all the geodesics of the same curvature joining two points. As a consequence, we solve the isoperimetric problem in H^1 assuming C^2 smoothness of the solutions. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "9 . ( 761 ) Rectifiability of Singular Sets in Noncollapsed Spaces with Ricci   Curvature bounded below \n",
      " [ Cosine Similarity= 0.879 ]\n",
      "\n",
      "\n",
      "   This paper is concerned with the structure of GromovHausdorff limit spaces  of Riemannian manifolds satisfying a uniform lower Ricci curvature bound  as well as the noncollapsing assumption . In such cases, there is a filtration of the singular set, , where x; equivalently no tangent cone splits off a Euclidean factor  isometrically. Moreover, by , . However, little else has been understood about the structure of the singular set .   Our first result for such limit spaces  states that  is rectifiable. In fact, we will show that for a.e. , {\\it every} tangent cone  at  is symmetric i.e. that  where  might depend on the particular . We use this to show that there exists , and a rectifible set , with finite dimensional Hausdorff measure , such that  is biH\\\"older equivalent to a smooth riemannian manifold. This improves the regularity results of . Additionally, we will see that tangent cones are unique of a subset of Hausdorff  dimensional measure zero.   Our analysis is based on several new ideas, including a sharp conesplitting theorem and a geometric transformation theorem, which will allow us to control the degeneration of harmonic functions on these neck regions. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "10 . ( 14811 ) Singularity of the spectrum for smooth areapreserving flows in genus   two and translation surfaces well approximated by cylinders \n",
      " [ Cosine Similarity= 0.879 ]\n",
      "\n",
      "\n",
      "   We consider smooth flows preserving a smooth invariant measure, or, equivalently, locally Hamiltonian flows on compact orientable surfaces and show that, when the genus of the surface is two, almost every such locally Hamiltonian flow with two non degenerate isomorphic saddle has singular spectrum. More in general, singularity of the spectrum holds for special flows over a full measure set of interval exchange transformations with a hyperelliptic permutation (of any number of exchanged intervals), under a roof with symmetric logarithmic singularities. The result is proved using a criterion for singularity based on tightness of Birkhoff sums with exponential tails decay. A key ingredient in the proof, which is of independent interest, is a result on translation surfaces well approximated by single cylinders. We show that for almost every translation surface in any connected component of any stratum there exists a full measure set of directions which can be well approximated by a single cylinder of area arbitrarily close to one. The result, in the special case of the stratum , yields rigidity sets needed for the singularity result. \n",
      "\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------- Doc2Vec Model (Dist. Memory)-----------------\\n\")\n",
    "display_results(df_rec_d2v_dm, df_ethan_new_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f802a",
   "metadata": {},
   "source": [
    "### Jee Uhn's Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e354ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jeeuhn = user_data(jeeuhn)\n",
    "df_jeeuhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Using the pretrained Word2Vec\n",
    "df_rec_wv2, df_jeeuhn_new_wv = n_recommendations(w2v_model, df, df_jeeuhn[0:2], 10)\n",
    "\n",
    "print(\"--------------------- Word2Vec Model ---------------------\\n\")\n",
    "display_results(df_rec_wv2, df_jeeuhn_new_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eacb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Using Doc2Vec with Distributed Bag of Words\n",
    "df_rec_d2v_bow2, df_jeeuhn_new_bow = n_recommendations(d2v_model_bow, df, df_jeeuhn[0:2], 10)\n",
    "\n",
    "print(\"----------------- Doc2Vec Model (Dist. Bag of Words)-----------------\\n\")\n",
    "display_results(df_rec_d2v_bow2, df_jeeuhn_new_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34257688",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Using Doc2Vec with Distributed Memory\n",
    "df_rec_d2v_dm2, df_jeeuhn_new_dm = n_recommendations(d2v_model_dm, df, df_jeeuhn[0:2], 10)\n",
    "\n",
    "print(\"----------------- Doc2Vec Model (Dist. Memory)-----------------\\n\")\n",
    "display_results(df_rec_d2v_dm2, df_jeeuhn_new_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb39d28",
   "metadata": {},
   "source": [
    "### Mike's Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bcdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mike = user_data(mike)\n",
    "df_mike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Using the pretrained Word2Vec\n",
    "df_rec_wv3, df_mike_new_wv = n_recommendations(w2v_model, df, df_mike[0:2], 10)\n",
    "\n",
    "print(\"--------------------- Word2Vec Model ---------------------\\n\")\n",
    "display_results(df_rec_wv3, df_mike_new_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c5ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Using Doc2Vec with Distributed Bag of Words\n",
    "df_rec_d2v_bow3, df_mike_new_bow = n_recommendations(d2v_model_bow, df, df_mike[0:2], 10)\n",
    "\n",
    "print(\"----------------- Doc2Vec Model (Dist. Bag of Words)-----------------\\n\")\n",
    "display_results(df_rec_d2v_bow3, df_mike_new_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Using Doc2Vec with Distributed Memory\n",
    "df_rec_d2v_dm3, df_mike_new_dm = n_recommendations(d2v_model_dm, df, df_mike[0:2], 10)\n",
    "\n",
    "print(\"----------------- Doc2Vec Model (Dist. Memory)-----------------\\n\")\n",
    "display_results(df_rec_d2v_dm3, df_mike_new_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4d800a",
   "metadata": {},
   "source": [
    "### Jenia's Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jenia = user_data(jenia)\n",
    "df_jenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Using the pretrained Word2Vec\n",
    "df_rec_wv4, df_jenia_new_wv = n_recommendations(w2v_model, df, df_jenia[0:2], 10)\n",
    "\n",
    "print(\"--------------------- Word2Vec Model ---------------------\\n\")\n",
    "display_results(df_rec_wv4, df_jenia_new_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Using Doc2Vec with Distributed Bag of Words\n",
    "df_rec_d2v_bow4, df_jenia_new_bow = n_recommendations(d2v_model_bow, df, df_jenia[0:2], 10)\n",
    "\n",
    "print(\"----------------- Doc2Vec Model (Dist. Bag of Words)-----------------\\n\")\n",
    "display_results(df_rec_d2v_bow4, df_jenia_new_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b575ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Using Doc2Vec with Distributed Memory\n",
    "df_rec_d2v_dm4, df_jenia_new_dm = n_recommendations(d2v_model_dm, df, df_jenia[0:2], 10)\n",
    "\n",
    "print(\"----------------- Doc2Vec Model (Dist. Memory)-----------------\\n\")\n",
    "display_results(df_rec_d2v_dm4, df_jenia_new_dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
