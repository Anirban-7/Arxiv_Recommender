{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwb6boWwz1Ac"
   },
   "source": [
    "# Heirarchal topic modeling analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45iQJ14g0oZe"
   },
   "source": [
    "## Goal\n",
    "\n",
    "\n",
    " We perform a topic analysis on a dataset consisting of arxiv pre-prints based on their titles and abstracts.\n",
    "\n",
    "## The dataset\n",
    "\n",
    "Our dataset contains the metadata from a uniform sample of 20,000 papers among those with subject tags in the following list:\n",
    "\n",
    "Dynamical systems, PDEs, Mathematical Physics, Probability, and Differential Geometry.\n",
    "\n",
    "## Layout of this notebook\n",
    "\n",
    "1. Preliminary analysis of the data\n",
    "1. Creating the basic topic model structure\n",
    "1. Creating the evaluation metrics\n",
    "1. Tuning hyper-parameters\n",
    "1. Evaluating performance of the model on a test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tS8K0qHpa1Hu",
    "outputId": "c88564e8-7987-4d04-daa5-5655605eba11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Arxiv_Recommender'...\n",
      "remote: Enumerating objects: 304, done.\u001b[K\n",
      "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 304 (delta 31), reused 35 (delta 29), pack-reused 264\u001b[K\n",
      "Receiving objects: 100% (304/304), 598.54 MiB | 26.21 MiB/s, done.\n",
      "Resolving deltas: 100% (143/143), done.\n",
      "Updating files: 100% (53/53), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/Anirban-7/Arxiv_Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xSSYh9Qa2w4",
    "outputId": "35e5f93f-4f4f-455c-a22f-fc9bc315779f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Arxiv_Recommender\n"
     ]
    }
   ],
   "source": [
    "cd /content/Arxiv_Recommender/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgaTlGbd0IPq"
   },
   "source": [
    "# 1. Create the basic topic model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6CIMIA55H-u"
   },
   "source": [
    "## Create the basic UMAP, KMeans, and HDBSCAN objects we will modify when tuning hyper-parameters\n",
    "\n",
    "Below we create two instances of BERTopic models. One will be responsible for the initial K-means clustering and the second will be the template for the 5 topic models fit on each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3miLxAik0ZpW",
    "outputId": "21804fe3-51b6-4fc0-83e8-6a3177580c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting arxiv\n",
      "  Downloading arxiv-1.4.7-py3-none-any.whl (12 kB)\n",
      "Collecting feedparser (from arxiv)\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sgmllib3k (from feedparser->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=3a746aac291492e79765a6bb22ae8d591db394b45d09b849cb9bb9999b199dff\n",
      "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "Successfully installed arxiv-1.4.7 feedparser-6.0.10 sgmllib3k-1.0.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting bertopic\n",
      "  Downloading bertopic-0.15.0-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.22.4)\n",
      "Collecting hdbscan>=0.8.29 (from bertopic)\n",
      "  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting umap-learn>=0.5.0 (from bertopic)\n",
      "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.2.2)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.65.0)\n",
      "Collecting sentence-transformers>=0.4.1 (from bertopic)\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.13.1)\n",
      "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (0.29.34)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2022.7.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (8.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.15.2+cu118)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.56.4)\n",
      "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2023.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (23.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (67.7.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (16.0.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.10.31)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (8.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.1.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
      "Building wheels for collected packages: hdbscan, sentence-transformers, umap-learn, pynndescent\n",
      "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp310-cp310-linux_x86_64.whl size=3541984 sha256=cf0b36ba3f17d7cbd1f3005d12e9d70374631ce81f76bf1a8a10290a040b5961\n",
      "  Stored in directory: /root/.cache/pip/wheels/dc/52/e3/6c6b60b126b4d5c4370cb5ac071b82950f91649d62d72f7f56\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=6a6255401311f562fdc0546be3066d1389628da76e451d629b1394cdb621d268\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82816 sha256=f95fcf31c44bfd1e1d9b46a82857236ec98e47dcadddcdf90d4dc49913a9b751\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
      "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=7e1c1ad90625409dd1b5847c40664f8ecd7b887b65e3b0c7617f66c48c6e0309\n",
      "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
      "Successfully built hdbscan sentence-transformers umap-learn pynndescent\n",
      "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, pynndescent, hdbscan, umap-learn, sentence-transformers, bertopic\n",
      "Successfully installed bertopic-0.15.0 hdbscan-0.8.29 huggingface-hub-0.15.1 pynndescent-0.5.10 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.29.2 umap-learn-0.5.3\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.29.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "## Install necessary packages\n",
    "!pip install arxiv\n",
    "!pip install bertopic\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Vmyy3sCy5aZc"
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3cBl4Qb6L6y"
   },
   "outputs": [],
   "source": [
    "## Create the umap objects\n",
    "\n",
    "# UMAP for K-means step\n",
    "kmeans_proj = UMAP(n_neighbors=15,n_components=5,metric='euclidean',min_dist=0.0,random_state=623)\n",
    "\n",
    "# UMAP for subtopic clustering\n",
    "cluster_proj = UMAP(n_neighbors=15, n_components=5,metric='euclidean',min_dist=0.0,random_state=623)\n",
    "\n",
    "# UMAP for visualizing the document clustering in two dimensions during evaluation.\n",
    "vis_proj = UMAP(n_neighbors=15,n_components=2,metric='euclidean',min_dist=0.0,random_state=623)\n",
    "\n",
    "## We use a fixed random state to eliminate stochastic effects in tuning hyperparameters and to compare to the global topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZ1p32Id6-xA"
   },
   "outputs": [],
   "source": [
    "## Create clusterers\n",
    "\n",
    "# K-means\n",
    "kmeans_clusterer = KMeans(5) #k = 5 reflects the major presence of 5 distinct subjects.\n",
    "\n",
    "# HDBSCAN for fine clustering\n",
    "subclusterer = HDBSCAN(min_cluster_size=10,min_samples=10,max_cluster_size=0,metric='euclidean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLniMC938_9m"
   },
   "outputs": [],
   "source": [
    "## Create the two kinds of topic model architecture\n",
    "\n",
    "\n",
    "\n",
    "# K-means\n",
    "base_topic_model = BERTopic(umap_model=kmeans_proj,\n",
    "                            hdbscan_model=kmeans_clusterer,\n",
    "                            vectorizer_model=vectorizer,\n",
    "                            representation_model=rep_model,\n",
    "                            verbose=True)\n",
    "\n",
    "# Fine clustering\n",
    "cluster_topic_model = BERTopic(umap_model=cluster_proj,\n",
    "                            hdbscan_model=subclusterer,\n",
    "                            vectorizer_model=vectorizer,\n",
    "                            representation_model=rep_model,\n",
    "                            verbose=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nu7htUXJj54L"
   },
   "source": [
    "## Create the two-step model and define fitting and predicting methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqZdZHWiXDCP"
   },
   "source": [
    "We first decide the hyper-parameters we will tune. Note that we use the same bertopic model for each cluster model in order to simplify the procedure. Therefore we have \n",
    "\n",
    "We need to choose parameters of **two** bertopic models. We won't modify the respresentation of topics but rather the UMAP and clustering parameters.\n",
    "\n",
    "Model 1: UMAP and K-means clustering parameters.\n",
    "Model 2: UMAP and HDBSCAN clustering parameters.\n",
    "\n",
    "We write a function which takes two arguments model_1_params and model_2_params.\n",
    "it returns a tuple (kmeans_model , cluster_model). The second we will run inside every cluster produced by the first.\n",
    "\n",
    "To input the parameters of the models, we use a dictionary \n",
    "\n",
    "kmeans_model_params = { 'umap' : umap_params }\n",
    "cluster_model_params = {'umap': umap_params , 'hdbscan': hdbscan_params}\n",
    "\n",
    "Note that we don't change the kmeans clusterer itself because there are essentially no parameters to tune.\n",
    "\n",
    "Each of the umap and hdbscan parameters will be packaged as a kwarg and unpacked with **.\n",
    "\n",
    "umap_params = {'n_neighbors':15 , 'n_components':5, 'metric':'euclidean','min_dist':0.0, 'random_state':623}\n",
    "\n",
    "hdbscan_params = {'min_cluster_size':10, 'min_samples' : 10, 'max_cluster_size' : 0, 'metric' : 'euclidean'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "FS5mZghTYzZf"
   },
   "outputs": [],
   "source": [
    "## Fix the parameters we will vary and construct the full set of model parameters from these\n",
    "\n",
    "def get_model_params(umap_n_neighbors=15, umap_n_components=5,hdbscan_min_cluster_size=10, hdbscan_min_samples=10):\n",
    "\n",
    "  umap_params = {'n_neighbors':15 , 'n_components':5, 'metric':'euclidean','min_dist':0.0, 'random_state':623}\n",
    "  hdbscan_params = {'min_cluster_size':10, 'min_samples' : 10, 'max_cluster_size' : 0, 'metric' : 'euclidean', 'prediction_data':'True'}\n",
    "\n",
    "  kmeans_model_params = {'umap' : umap_params} \n",
    "  cluster_model_params = {'umap' : umap_params, 'hdbscan': hdbscan_params}\n",
    "\n",
    "  return kmeans_model_params , cluster_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "25Mi3aD6qblU"
   },
   "outputs": [],
   "source": [
    "def construct_models(kmeans_model_params , cluster_model_params):\n",
    "  # Construct umap objects \n",
    "\n",
    "  kmeans_proj = UMAP(**kmeans_model_params['umap'])\n",
    "  cluster_proj = UMAP(**cluster_model_params['umap'])\n",
    "\n",
    "  # Construct clusterers\n",
    "  kmeans_clusterer = KMeans(n_clusters=5)\n",
    "  hdbscan_clusterer = HDBSCAN(**cluster_model_params['hdbscan'])\n",
    "\n",
    "  # Construct topic representation\n",
    "  vectorizer = CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "  rep_model = MaximalMarginalRelevance(diversity=0.5)\n",
    "\n",
    "  # K-means\n",
    "  base_topic_model = BERTopic(umap_model=kmeans_proj,\n",
    "                              hdbscan_model=kmeans_clusterer,\n",
    "                              vectorizer_model=vectorizer,\n",
    "                              representation_model=rep_model,\n",
    "                              verbose=True)\n",
    "\n",
    "  # Fine clustering\n",
    "  cluster_topic_model = BERTopic(umap_model=cluster_proj,\n",
    "                              hdbscan_model=hdbscan_clusterer,\n",
    "                              vectorizer_model=vectorizer,\n",
    "                              representation_model=rep_model,\n",
    "                              verbose=True) \n",
    "\n",
    "  return base_topic_model , cluster_topic_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wT2JU78LeYU"
   },
   "source": [
    "#### Create the fit_model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XF9rsxbm-8no"
   },
   "outputs": [],
   "source": [
    "## Define the function which trains the models.\n",
    "## More precisely, we are using the dataframe 'library.parquet'\n",
    "## which contains the columns -- 'doc_strings' and\n",
    "## 'doc_strings_reduced'. This is the corpus of papers \n",
    "## on which we do topic analysis. These columns are the\n",
    "## exact text strings that are fed into the specter\n",
    "## sentence embedding model to generate the vector embeddings\n",
    "## we cluster. The 'reduced' argument tells us whether to use\n",
    "## the titles + abstracts which have had rare words removed\n",
    "## as well as latex (reduced = True) vs just the latex removed.\n",
    "\n",
    "def fit_models(base_topic_model,cluster_topic_model,reduced=False):\n",
    "  \"\"\"\n",
    "  Arguments:\n",
    "\n",
    "  reduced: Boolean determining whether we use the\n",
    "    reduced title + abstract or the minimally cleaned title + abstract\n",
    "  base_topic_model: a bertopic model which does the\n",
    "    first step k-means clustering\n",
    "  cluster_topic_model: a bertopic model which does the\n",
    "    second step of topic identification within each cluster.\n",
    "\n",
    "  Returns:\n",
    "\n",
    "  A 3 tuple consisting of the\n",
    "    (a) trained kmeans model,\n",
    "    (b) a dictionary of trained cluster models,\n",
    "    (c) the dataframe returned with two additional columns.\n",
    "        The new columns are\n",
    "        1. 'kmeans_labels' : the numerical label 0-4 which\n",
    "          corresponds to the k-means cluster the document belongs to\n",
    "        2. 'fine_topic_labels' : -1 if the document is an outlier\n",
    "          within its cluster. Otherwise, it is a list of the keywords\n",
    "          generated that best describes the topic assigned to the document. \n",
    "  \"\"\"\n",
    "  df = pd.read_parquet('./final_data/library.parquet')\n",
    "\n",
    "  if reduced:\n",
    "    embeddings = pd.read_parquet('./final_data/library_vec_reduced_specter.parquet').values\n",
    "    docs = 'doc_string_reduced'\n",
    "  else:\n",
    "    embeddings = pd.read_parquet('./final_data/library_vec_specter.parquet').values\n",
    "    docs = 'doc_string'\n",
    "\n",
    "  # First train the K-means model.\n",
    "  print('Finding the K-means clusters...')\n",
    "  base_topic_model.fit(documents=df[docs].to_list(), embeddings=embeddings)\n",
    "\n",
    "  # Create a new column in the dataframe\n",
    "  # called 'kmeans_labels' which records\n",
    "  # the topic label for each paper\n",
    "  kmeans_labels = pd.Series(base_topic_model.topics_, index=df.index)\n",
    "  df['kmeans_labels'] = kmeans_labels\n",
    "\n",
    "  # Construct dictionary of cluster models\n",
    "  cluster_models = {i : cluster_topic_model for i in range(5)}\n",
    "\n",
    "  # Add a placeholder column for the fine topic labels\n",
    "  df['fine_topic_labels'] = 0\n",
    "\n",
    "  for i in range(5):\n",
    "    print(f'Getting topics for cluster {i}...')\n",
    "    \n",
    "    # Get the papers in kmeans topic i\n",
    "    indices = df.loc[df['kmeans_labels'] == i].index\n",
    "\n",
    "    # Get the documents in this topic\n",
    "    cluster_docs = df[docs].iloc[indices].to_list()\n",
    "\n",
    "    # Get the embeddings for these documents\n",
    "    cluster_embeddings = embeddings[indices,:]\n",
    "\n",
    "    # Train the ith model\n",
    "    cluster_models[i].fit(documents=cluster_docs,embeddings=cluster_embeddings)\n",
    "\n",
    "    # Create the topic labels dataframe\n",
    "    topics = cluster_models[i].topics_\n",
    "    labels = cluster_models[i].generate_topic_labels(nr_words=10,separator=' | ')\n",
    "\n",
    "    \n",
    "    def get_keywords(i):\n",
    "      return labels[i+1]\n",
    "\n",
    "    fine_topic_info = pd.DataFrame({'topic_number': topics}, index=indices)\n",
    "    fine_topic_info['topic_keywords'] = fine_topic_info['topic_number'].apply(func=get_keywords)\n",
    "\n",
    "    # Replace the keywords by -1 if the row is an outlier\n",
    "    fine_topic_info['topic_keywords'].loc[fine_topic_info['topic_number'] == -1] = -1\n",
    "\n",
    "    df['fine_topic_labels'].iloc[indices] = fine_topic_info['topic_keywords']\n",
    "\n",
    "  return base_topic_model , cluster_models , df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHQesK-BLbT1"
   },
   "source": [
    "#### Create the predict_topics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "TmSt7MRhLo09"
   },
   "outputs": [],
   "source": [
    "## This will work very similarly to the fit function.\n",
    "\n",
    "## We assume we are given a dataframe consisting\n",
    "## of test documents. The column 'doc_strings'\n",
    "## contains the text that was used to generate\n",
    "## the embedding of each document (cleaned title\n",
    "## and abstract). The strip_cat column contains\n",
    "## the arxiv math subject tags in the form of a list\n",
    "## where each is represented by its two-letter code.\n",
    "## e.g. Dynamical Systems is 'DS'.\n",
    "## The goal is to return the test dataframe with the\n",
    "## same two additional columns that the fit method constructs. \n",
    "\n",
    "def predict_topics(test_path,test_embeddings_path,trained_base_model,trained_cluster_models):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "\n",
    "\n",
    "\n",
    "  Returns: The dataframe that was passed with two additional\n",
    "  columns. The new columns are\n",
    "    1. 'kmeans_labels' : the numerical label 0-4 which corresponds\n",
    "      to the k-means cluster the document belongs to\n",
    "    2. 'fine_topic_labels' : -1 if the document is an outlier within\n",
    "      its cluster. Otherwise, it is a list of the keywords generated\n",
    "      that best describes the topic assigned to the document. \n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "  test = pd.read_csv(test_path)\n",
    "  test_embeddings = pd.read_parquet(test_embeddings_path).values  \n",
    "\n",
    "\n",
    "  ## Trained cluster models are encoded as a dictionary with\n",
    "  # keys 0-4 representing the name of K-means cluster it was trained on.\n",
    "\n",
    "  # Grab the documents the embeddings were trained on\n",
    "  docs = test['doc_string'].to_list()\n",
    "  \n",
    "  # Predict the K-means topic of each paper and store these as a series\n",
    "  print('Predicting K-means clusters for each document...')\n",
    "  kmeans_label_list , _ = trained_base_model.transform(documents=docs, embeddings=test_embeddings)\n",
    "  kmeans_labels = pd.Series(kmeans_label_list,index=test.index)\n",
    "  \n",
    "  # Add K-means labels to the dataframe\n",
    "  test['kmeans_labels'] = kmeans_labels\n",
    "\n",
    "  # Add a placeholder column for the fine topic labels\n",
    "  test['fine_topic_labels'] = 0\n",
    "\n",
    "\n",
    "  for i in range(5):\n",
    "    print(f'Predicting topic labels for cluster {i}...')\n",
    "\n",
    "    # Get the papers in kmeans topic i\n",
    "    indices = test.loc[test['kmeans_labels'] == i].index\n",
    "\n",
    "    # Get the documents in this topic\n",
    "    cluster_docs = test['doc_string'].iloc[indices].to_list()\n",
    "\n",
    "    # Get the embeddings for these documents\n",
    "    cluster_embeddings = test_embeddings[indices,:]\n",
    "\n",
    "    # Get the predicted topics for this cluster\n",
    "    topics , _ = trained_cluster_models[i].transform(documents=cluster_docs,embeddings=cluster_embeddings)\n",
    "    labels = trained_cluster_models[i].generate_topic_labels(nr_words=10,separator=' | ')\n",
    "    \n",
    "    def get_keywords(i):\n",
    "      return labels[i]\n",
    "\n",
    "    fine_topic_info = pd.DataFrame({'topic_number': topics}, index=indices)\n",
    "    fine_topic_info['topic_keywords'] = fine_topic_info['topic_number'].apply(func=get_keywords)\n",
    "\n",
    "    # Replace the keywords by -1 if the row is an outlier\n",
    "    fine_topic_info['topic_keywords'].loc[fine_topic_info['topic_number'] == -1] = -1\n",
    "\n",
    "    test['fine_topic_labels'].iloc[indices] = fine_topic_info['topic_keywords']\n",
    "\n",
    "  return test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pHR9Pi4KbSh"
   },
   "source": [
    "## Testing the 'fit' function on our dataset with default model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "collapsed": true,
    "id": "0J1BYMkzqLS_",
    "outputId": "e88838f8-0f95-4339-d109-7dd5f5b6fa1c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4b270eeaae97>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m## Construct models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mbase_topic_model\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcluster_topic_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans_model_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkmeans_model_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcluster_model_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster_model_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-f1445a37d3aa>\u001b[0m in \u001b[0;36mconstruct_models\u001b[0;34m(kmeans_model_params, cluster_model_params)\u001b[0m\n\u001b[1;32m     12\u001b[0m   base_topic_model = BERTopic(umap_model=kmeans_proj,\n\u001b[1;32m     13\u001b[0m                               \u001b[0mhdbscan_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkmeans_clusterer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                               \u001b[0mvectorizer_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                               \u001b[0mrepresentation_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrep_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                               verbose=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "\n",
    "## Define default parameters\n",
    "\n",
    "default_umap_params = {'n_neighbors':15 , 'n_components':5, 'metric':'euclidean','min_dist':0.0, 'random_state':623}\n",
    "default_hdbscan_params = {'min_cluster_size':10, 'min_samples' : 10, 'max_cluster_size' : 0, 'metric' : 'euclidean'}\n",
    "\n",
    "kmeans_model_params = {'umap' : default_umap_params}\n",
    "cluster_model_params = {'umap' : default_umap_params , 'hdbscan': default_hdbscan_params}\n",
    "\n",
    "## Construct models\n",
    "\n",
    "base_topic_model , cluster_topic_model = construct_models(kmeans_model_params=kmeans_model_params,cluster_model_params=cluster_model_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "VNvWhVKRMPWX",
    "outputId": "b4cf4a5c-f1e1-422e-e7fa-3656515c7be4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4a5239d1-713e-4429-843c-a65b870bef45\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_raw</th>\n",
       "      <th>abstract_raw</th>\n",
       "      <th>update_date</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182244</th>\n",
       "      <td>1412.3275</td>\n",
       "      <td>Limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>We study the maximum number of limit cycles ...</td>\n",
       "      <td>2014-12-11</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196425</th>\n",
       "      <td>0809.3510</td>\n",
       "      <td>Shrinking Point Bifurcations of Resonance Tong...</td>\n",
       "      <td>Resonance tongues are mode-locking regions o...</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479424</th>\n",
       "      <td>2201.04222</td>\n",
       "      <td>Classification of Codimension-1 Singular Bifur...</td>\n",
       "      <td>The study of bifurcations of differential-al...</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Ovsyannikov', 'Ivan', ''], ['Ruan', 'Haibo'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176385</th>\n",
       "      <td>1408.5812</td>\n",
       "      <td>Partial sums of excursions along random geodes...</td>\n",
       "      <td>For a non-uniform lattice in SL(2,R), we con...</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>[GT, DS]</td>\n",
       "      <td>[['Gadre', 'Vaibhav', '']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291058</th>\n",
       "      <td>1707.03102</td>\n",
       "      <td>Uniform dimension results for a family of Mark...</td>\n",
       "      <td>In this paper we prove uniform Hausdorff and...</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>[PR]</td>\n",
       "      <td>[['Sun', 'Xiaobin', ''], ['Xiao', 'Yimin', '']...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a5239d1-713e-4429-843c-a65b870bef45')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4a5239d1-713e-4429-843c-a65b870bef45 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4a5239d1-713e-4429-843c-a65b870bef45');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                id                                          title_raw  \\\n",
       "182244   1412.3275  Limit cycles bifurcating from a degenerate center   \n",
       "196425   0809.3510  Shrinking Point Bifurcations of Resonance Tong...   \n",
       "479424  2201.04222  Classification of Codimension-1 Singular Bifur...   \n",
       "176385   1408.5812  Partial sums of excursions along random geodes...   \n",
       "291058  1707.03102  Uniform dimension results for a family of Mark...   \n",
       "\n",
       "                                             abstract_raw update_date  \\\n",
       "182244    We study the maximum number of limit cycles ...  2014-12-11   \n",
       "196425    Resonance tongues are mode-locking regions o...  2015-05-13   \n",
       "479424    The study of bifurcations of differential-al...  2022-01-13   \n",
       "176385    For a non-uniform lattice in SL(2,R), we con...  2014-10-09   \n",
       "291058    In this paper we prove uniform Hausdorff and...  2017-10-03   \n",
       "\n",
       "       strip_cat                                     authors_parsed  \n",
       "182244      [DS]      [['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]  \n",
       "196425      [DS]  [['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....  \n",
       "479424      [DS]  [['Ovsyannikov', 'Ivan', ''], ['Ruan', 'Haibo'...  \n",
       "176385  [GT, DS]                         [['Gadre', 'Vaibhav', '']]  \n",
       "291058      [PR]  [['Sun', 'Xiaobin', ''], ['Xiao', 'Yimin', '']...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the library\n",
    "\n",
    "library = pd.read_parquet('./data/library.parquet')\n",
    "library.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eZPWZFDpMnlU"
   },
   "outputs": [],
   "source": [
    "## Load the library embeddings:\n",
    "\n",
    "# library_vec_reduced_specter = pd.read_parquet('./final_data/library_vec_reduced_specter.parquet')\n",
    "# library_vec_specter = pd.read_parquet('./final_data/library_vec_specter.parquet')\n",
    "\n",
    "## Load the dev set embeddings:\n",
    "\n",
    "# dev_vec_specter = pd.read_parquet('./final_data/dev_vec_specter.parquet')\n",
    "\n",
    "## Load the test set embeddings:\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxjGQ3idNMAh"
   },
   "outputs": [],
   "source": [
    "## Create the fitted model and get topics for the library\n",
    "\n",
    "trained_base , trained_clusters , results = fit_models(df=library,\n",
    "                                                       reduced=False,\n",
    "                                                       base_topic_model=base_topic_model,\n",
    "                                                       cluster_topic_model=cluster_topic_model)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1U46Chh5cDYV"
   },
   "source": [
    "## 3. Creating the evaluation metrics\n",
    "\n",
    "Next we will evaluate the topic model on a dev set of 50 brand new articles that are not present in the dataset. We will measure\n",
    "\n",
    "1. The fraction of outliers per subject tag on the entire dataset\n",
    "2. The fraction of outlier predictions in the dev set\n",
    "3. The (subjective) accuracy of the predicted key-words. \n",
    "\n",
    "To the third point, the last 1/5 of the dev set consists of papers that Jee uhn and I will be confident in categorizing. The others will be a rough eye-test by non-experts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "Yzt-oeaDnXWf"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def OHE_cats(df):\n",
    "    \"\"\"Return a DataFrame of one-hot-encoded categories of the library with\n",
    "    the same index as the library\n",
    "    \"\"\"\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    categories = data_utils.category_map()\n",
    "\n",
    "    def convert_to_eng(cat_array):\n",
    "      out = []\n",
    "      for tag in cat_array:\n",
    "        if ('math.' + tag) not in categories.keys():\n",
    "          continue\n",
    "        else:\n",
    "          out.append(categories['math.' + tag])\n",
    "        return out\n",
    "\n",
    "    def func_to_apply(cat_array):\n",
    "      if convert_to_eng(cat_array):\n",
    "        return convert_to_eng(cat_array)\n",
    "      else:\n",
    "        return 'Unknown'\n",
    "\n",
    "    eng_cats = df['strip_cat'].apply(func_to_apply)\n",
    "    OHE_array = mlb.fit_transform(eng_cats)\n",
    "    \n",
    "    return pd.DataFrame(OHE_array,columns=mlb.classes_,index=df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "028QMKfwXXuz"
   },
   "outputs": [],
   "source": [
    "## Define a function to get outlier information.\n",
    "## This will take in the results of predicting\n",
    "## topics and return a dataframe showing the\n",
    "## breakdown of total # of outliers per subject tag,\n",
    "## as well as the ratio of outliers per subject tag.\n",
    "\n",
    "def get_outlier_stats(results):\n",
    "\n",
    "  total_subject_count = OHE_cats(results).sum(axis=0)\n",
    "  outliers = results.loc[results['fine_topic_labels'] == -1] \n",
    "  outlier_subject_count = OHE_cats(outliers).sum(axis=0)\n",
    "  outlier_subject_ratio = outlier_subject_count / total_subject_count\n",
    "\n",
    "  return pd.concat({'outlier_subject_count' : outlier_subject_count, 'outlier_subject_ratio': outlier_subject_ratio})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "P4RCJnTmZfNI"
   },
   "outputs": [],
   "source": [
    "## Define a function taking in the results of topic model prediction and returning the predicted topics as well as the outlier stats\n",
    "\n",
    "def eval_predictions(results):\n",
    "  \n",
    "  predicted_topics = results[['title_raw','abstract_raw','fine_topic_labels']].loc[results['fine_topic_labels'] != -1]\n",
    "\n",
    "  return predicted_topics , get_outlier_stats(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWbdMPCMTtMN"
   },
   "source": [
    "## 4. Define the hyper-parameter tuning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "tnvZ4ieDTyox"
   },
   "outputs": [],
   "source": [
    "## 1. Specify the hyper-parameters needed to build the UMAP and HDBSCAN objects\n",
    "\n",
    "kmeans_model_params , cluster_model_params = get_model_params(umap_n_neighbors=15,\n",
    "                                                              umap_n_components=5,\n",
    "                                                              hdbscan_min_cluster_size=10,\n",
    "                                                              hdbscan_min_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "t6MtGc6GT5mR"
   },
   "outputs": [],
   "source": [
    "## 2. Construct the cluster models\n",
    "\n",
    "base_topic_model , cluster_topic_model = construct_models(kmeans_model_params , cluster_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hdjm_oT8UTl5",
    "outputId": "377b314b-bcaa-4403-ac6e-9a8a86e2fce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the K-means clusters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:31:06,954 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:31:09,632 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting topics for cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:31:43,642 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:31:43,870 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting topics for cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:32:01,569 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:32:01,771 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting topics for cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:32:30,103 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:32:30,275 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting topics for cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:32:57,093 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:32:57,269 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting topics for cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:33:13,020 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:33:13,122 - BERTopic - Clustered reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "## Fit the models\n",
    "\n",
    "trained_base_model , trained_cluster_models , fit_library = fit_models(base_topic_model,cluster_topic_model,reduced=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUMLTVJuUi99",
    "outputId": "3418295a-9975-4c4d-e90d-38baa5876881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting K-means clusters for each document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:45:09,795 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:45:09,801 - BERTopic - Predicted clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting topic labels for cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:45:10,774 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:45:10,780 - BERTopic - Predicted clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting topic labels for cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:45:11,687 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:45:11,692 - BERTopic - Predicted clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting topic labels for cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:45:12,621 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:45:12,626 - BERTopic - Predicted clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting topic labels for cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:45:13,528 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:45:13,533 - BERTopic - Predicted clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting topic labels for cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 05:45:14,415 - BERTopic - Reduced dimensionality\n",
      "2023-06-02 05:45:14,417 - BERTopic - Predicted clusters\n"
     ]
    }
   ],
   "source": [
    "## Predict topics on the dev set\n",
    "\n",
    "dev_predictions = predict_topics(test_path='./final_data/clean_dev_set.csv',\n",
    "               test_embeddings_path='./final_data/dev_vec_specter.parquet',\n",
    "               trained_base_model=trained_base_model,\n",
    "               trained_cluster_models=trained_cluster_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "d219Bi1rXEAN"
   },
   "outputs": [],
   "source": [
    "## Get the evaluation metrics\n",
    "\n",
    "eye_test , outlier_stats = eval_predictions(dev_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "id": "pDqFTjS4dCQf",
    "outputId": "f8ca5c00-5e84-4392-a60b-3aff505dd506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier_subject_count  Algebraic Geometry              150.000000\n",
      "                       Algebraic Topology               36.000000\n",
      "                       Analysis of PDEs               1634.000000\n",
      "                       Category Theory                   8.000000\n",
      "                       Classical Analysis and ODEs     110.000000\n",
      "                                                         ...     \n",
      "outlier_subject_ratio  Representation Theory             0.457831\n",
      "                       Rings and Algebras                0.517241\n",
      "                       Spectral Theory                   0.415094\n",
      "                       Statistics Theory                 0.422018\n",
      "                       Symplectic Geometry               0.412162\n",
      "Length: 64, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-74f0b76b-30d5-4aae-ac01-cf748c77bc05\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title_raw</th>\n",
       "      <th>abstract_raw</th>\n",
       "      <th>update_date</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>abstract_clean</th>\n",
       "      <th>authors_clean</th>\n",
       "      <th>abstract_tokenized</th>\n",
       "      <th>abstract_reduced_tokens</th>\n",
       "      <th>abstract_rejoin</th>\n",
       "      <th>doc_string</th>\n",
       "      <th>doc_string_reduced</th>\n",
       "      <th>kaggle_index</th>\n",
       "      <th>kmeans_labels</th>\n",
       "      <th>fine_topic_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182244</td>\n",
       "      <td>1412.3275</td>\n",
       "      <td>Limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>We study the maximum number of limit cycles ...</td>\n",
       "      <td>2014-12-11</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]</td>\n",
       "      <td>limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>we study the maximum number of limit cycles th...</td>\n",
       "      <td>[['llibre', 'j', ''], ['pantazi', 'c', '']]</td>\n",
       "      <td>[we, study, the, maximum, number, of, limit, c...</td>\n",
       "      <td>[we, study, the, maximum, number, of, limit, c...</td>\n",
       "      <td>we study the maximum number of limit cycles th...</td>\n",
       "      <td>limit cycles bifurcating from a degenerate cen...</td>\n",
       "      <td>limit cycles bifurcating from a degenerate cen...</td>\n",
       "      <td>182244</td>\n",
       "      <td>1</td>\n",
       "      <td>3 | bifurcation | bifurcations | hopf | hopf b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196425</td>\n",
       "      <td>0809.3510</td>\n",
       "      <td>Shrinking Point Bifurcations of Resonance Tong...</td>\n",
       "      <td>Resonance tongues are mode-locking regions o...</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....</td>\n",
       "      <td>shrinking point bifurcations of resonance tong...</td>\n",
       "      <td>resonance tongues are mode locking regions of ...</td>\n",
       "      <td>[['simpson', 'd j w', ''], ['meiss', 'j d', '']]</td>\n",
       "      <td>[resonance, tongues, are, mode, locking, regio...</td>\n",
       "      <td>[resonance, tongues, are, mode, locking, regio...</td>\n",
       "      <td>resonance tongues are mode locking regions of ...</td>\n",
       "      <td>shrinking point bifurcations of resonance tong...</td>\n",
       "      <td>shrinking point bifurcations of resonance tong...</td>\n",
       "      <td>196425</td>\n",
       "      <td>1</td>\n",
       "      <td>3 | bifurcation | bifurcations | hopf | hopf b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479424</td>\n",
       "      <td>2201.04222</td>\n",
       "      <td>Classification of Codimension-1 Singular Bifur...</td>\n",
       "      <td>The study of bifurcations of differential-al...</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>[['Ovsyannikov', 'Ivan', ''], ['Ruan', 'Haibo'...</td>\n",
       "      <td>classification of codimension singular bifurca...</td>\n",
       "      <td>the study of bifurcations of differential alge...</td>\n",
       "      <td>[['ovsyannikov', 'ivan', ''], ['ruan', 'haibo'...</td>\n",
       "      <td>[the, study, of, bifurcations, of, differentia...</td>\n",
       "      <td>[the, study, of, bifurcations, of, differentia...</td>\n",
       "      <td>the study of bifurcations of differential alge...</td>\n",
       "      <td>classification of codimension singular bifurca...</td>\n",
       "      <td>classification of codimension singular bifurca...</td>\n",
       "      <td>479424</td>\n",
       "      <td>1</td>\n",
       "      <td>3 | bifurcation | bifurcations | hopf | hopf b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176385</td>\n",
       "      <td>1408.5812</td>\n",
       "      <td>Partial sums of excursions along random geodes...</td>\n",
       "      <td>For a non-uniform lattice in SL(2,R), we con...</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>[GT, DS]</td>\n",
       "      <td>[['Gadre', 'Vaibhav', '']]</td>\n",
       "      <td>partial sums of excursions along random geodes...</td>\n",
       "      <td>for a non uniform lattice in slr we consider e...</td>\n",
       "      <td>[['gadre', 'vaibhav', '']]</td>\n",
       "      <td>[for, a, non, uniform, lattice, in, slr, we, c...</td>\n",
       "      <td>[for, a, non, uniform, lattice, in, slr, we, c...</td>\n",
       "      <td>for a non uniform lattice in slr we consider e...</td>\n",
       "      <td>partial sums of excursions along random geodes...</td>\n",
       "      <td>partial sums of excursions along random geodes...</td>\n",
       "      <td>176385</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291058</td>\n",
       "      <td>1707.03102</td>\n",
       "      <td>Uniform dimension results for a family of Mark...</td>\n",
       "      <td>In this paper we prove uniform Hausdorff and...</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>[PR]</td>\n",
       "      <td>[['Sun', 'Xiaobin', ''], ['Xiao', 'Yimin', '']...</td>\n",
       "      <td>uniform dimension results for a family of mark...</td>\n",
       "      <td>in this paper we prove uniform hausdorff and p...</td>\n",
       "      <td>[['sun', 'xiaobin', ''], ['xiao', 'yimin', '']...</td>\n",
       "      <td>[in, this, paper, we, prove, uniform, hausdorf...</td>\n",
       "      <td>[in, this, paper, we, prove, uniform, hausdorf...</td>\n",
       "      <td>in this paper we prove uniform hausdorff and p...</td>\n",
       "      <td>uniform dimension results for a family of mark...</td>\n",
       "      <td>uniform dimension results for a family of mark...</td>\n",
       "      <td>291058</td>\n",
       "      <td>0</td>\n",
       "      <td>8 | markov | chains | markov chains | chain | ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74f0b76b-30d5-4aae-ac01-cf748c77bc05')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-74f0b76b-30d5-4aae-ac01-cf748c77bc05 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-74f0b76b-30d5-4aae-ac01-cf748c77bc05');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    index          id                                          title_raw  \\\n",
       "0  182244   1412.3275  Limit cycles bifurcating from a degenerate center   \n",
       "1  196425   0809.3510  Shrinking Point Bifurcations of Resonance Tong...   \n",
       "2  479424  2201.04222  Classification of Codimension-1 Singular Bifur...   \n",
       "3  176385   1408.5812  Partial sums of excursions along random geodes...   \n",
       "4  291058  1707.03102  Uniform dimension results for a family of Mark...   \n",
       "\n",
       "                                        abstract_raw update_date strip_cat  \\\n",
       "0    We study the maximum number of limit cycles ...  2014-12-11      [DS]   \n",
       "1    Resonance tongues are mode-locking regions o...  2015-05-13      [DS]   \n",
       "2    The study of bifurcations of differential-al...  2022-01-13      [DS]   \n",
       "3    For a non-uniform lattice in SL(2,R), we con...  2014-10-09  [GT, DS]   \n",
       "4    In this paper we prove uniform Hausdorff and...  2017-10-03      [PR]   \n",
       "\n",
       "                                      authors_parsed  \\\n",
       "0      [['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]   \n",
       "1  [['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....   \n",
       "2  [['Ovsyannikov', 'Ivan', ''], ['Ruan', 'Haibo'...   \n",
       "3                         [['Gadre', 'Vaibhav', '']]   \n",
       "4  [['Sun', 'Xiaobin', ''], ['Xiao', 'Yimin', '']...   \n",
       "\n",
       "                                         title_clean  \\\n",
       "0  limit cycles bifurcating from a degenerate center   \n",
       "1  shrinking point bifurcations of resonance tong...   \n",
       "2  classification of codimension singular bifurca...   \n",
       "3  partial sums of excursions along random geodes...   \n",
       "4  uniform dimension results for a family of mark...   \n",
       "\n",
       "                                      abstract_clean  \\\n",
       "0  we study the maximum number of limit cycles th...   \n",
       "1  resonance tongues are mode locking regions of ...   \n",
       "2  the study of bifurcations of differential alge...   \n",
       "3  for a non uniform lattice in slr we consider e...   \n",
       "4  in this paper we prove uniform hausdorff and p...   \n",
       "\n",
       "                                       authors_clean  \\\n",
       "0        [['llibre', 'j', ''], ['pantazi', 'c', '']]   \n",
       "1   [['simpson', 'd j w', ''], ['meiss', 'j d', '']]   \n",
       "2  [['ovsyannikov', 'ivan', ''], ['ruan', 'haibo'...   \n",
       "3                         [['gadre', 'vaibhav', '']]   \n",
       "4  [['sun', 'xiaobin', ''], ['xiao', 'yimin', '']...   \n",
       "\n",
       "                                  abstract_tokenized  \\\n",
       "0  [we, study, the, maximum, number, of, limit, c...   \n",
       "1  [resonance, tongues, are, mode, locking, regio...   \n",
       "2  [the, study, of, bifurcations, of, differentia...   \n",
       "3  [for, a, non, uniform, lattice, in, slr, we, c...   \n",
       "4  [in, this, paper, we, prove, uniform, hausdorf...   \n",
       "\n",
       "                             abstract_reduced_tokens  \\\n",
       "0  [we, study, the, maximum, number, of, limit, c...   \n",
       "1  [resonance, tongues, are, mode, locking, regio...   \n",
       "2  [the, study, of, bifurcations, of, differentia...   \n",
       "3  [for, a, non, uniform, lattice, in, slr, we, c...   \n",
       "4  [in, this, paper, we, prove, uniform, hausdorf...   \n",
       "\n",
       "                                     abstract_rejoin  \\\n",
       "0  we study the maximum number of limit cycles th...   \n",
       "1  resonance tongues are mode locking regions of ...   \n",
       "2  the study of bifurcations of differential alge...   \n",
       "3  for a non uniform lattice in slr we consider e...   \n",
       "4  in this paper we prove uniform hausdorff and p...   \n",
       "\n",
       "                                          doc_string  \\\n",
       "0  limit cycles bifurcating from a degenerate cen...   \n",
       "1  shrinking point bifurcations of resonance tong...   \n",
       "2  classification of codimension singular bifurca...   \n",
       "3  partial sums of excursions along random geodes...   \n",
       "4  uniform dimension results for a family of mark...   \n",
       "\n",
       "                                  doc_string_reduced  kaggle_index  \\\n",
       "0  limit cycles bifurcating from a degenerate cen...        182244   \n",
       "1  shrinking point bifurcations of resonance tong...        196425   \n",
       "2  classification of codimension singular bifurca...        479424   \n",
       "3  partial sums of excursions along random geodes...        176385   \n",
       "4  uniform dimension results for a family of mark...        291058   \n",
       "\n",
       "   kmeans_labels                                  fine_topic_labels  \n",
       "0              1  3 | bifurcation | bifurcations | hopf | hopf b...  \n",
       "1              1  3 | bifurcation | bifurcations | hopf | hopf b...  \n",
       "2              1  3 | bifurcation | bifurcations | hopf | hopf b...  \n",
       "3              3                                                 -1  \n",
       "4              0  8 | markov | chains | markov chains | chain | ...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Look at the fitted library itself\n",
    "library_outlier_stats = get_outlier_stats(fit_library)\n",
    "\n",
    "\n",
    "print(library_outlier_stats)\n",
    "fit_library.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIRrBjfoXumb",
    "outputId": "738dd960-44b9-4cd3-c9c6-383a13d4c12a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outlier_subject_count  U    42.00\n",
       "                       k    42.00\n",
       "                       n    42.00\n",
       "                       o    42.00\n",
       "                       w    42.00\n",
       "outlier_subject_ratio  U     0.84\n",
       "                       k     0.84\n",
       "                       n     0.84\n",
       "                       o     0.84\n",
       "                       w     0.84\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Look at the outlier stats by subject\n",
    "outlier_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "dlVT-4_AX2Ck",
    "outputId": "4a0540a6-a894-47d3-f44f-9a34a6d70b4a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a69c880d-9640-4ea5-97e7-27b594fdfd85\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_raw</th>\n",
       "      <th>abstract_raw</th>\n",
       "      <th>fine_topic_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clustering and Arnoux-Rauzy words</td>\n",
       "      <td>We characterize the clustering of a word under...</td>\n",
       "      <td>22 | grassmannians | grassmann | grassmannian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Endemic Oscillations for SARS-CoV-2 Omicron --...</td>\n",
       "      <td>The SIRS model with constant vaccination and i...</td>\n",
       "      <td>2 | lie | lie algebras | algebras | lie groups...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A sub-Riemannian maximum modulus theorem</td>\n",
       "      <td>In this note we prove a sub-Riemannian maximum...</td>\n",
       "      <td>-1 | theory | quantum | field | algebra | spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>One-parameter discrete-time Calogero-Moser system</td>\n",
       "      <td>We present a new type of integrable one-dimens...</td>\n",
       "      <td>2 | lie | lie algebras | algebras | lie groups...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Boundary rigidity, and non-rigidity, of projec...</td>\n",
       "      <td>We investigate the property of boundary rigidi...</td>\n",
       "      <td>14 | symplectic | poisson | manifolds | manifo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>On the reduced space of multiplicative multive...</td>\n",
       "      <td>A strict Lie $2$-algebra $\\Gamma(\\wedge^\\bulle...</td>\n",
       "      <td>6 | branes | brane | calabi yau | yau | calabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Sharp bounds on the height of K-semistable tor...</td>\n",
       "      <td>Inspired by Fujita's algebro-geometric result ...</td>\n",
       "      <td>10 | string | boundary | entanglement | bulk |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Enumerative geometry via the moduli space of s...</td>\n",
       "      <td>In this paper we relate volumes of moduli spac...</td>\n",
       "      <td>10 | string | boundary | entanglement | bulk |...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a69c880d-9640-4ea5-97e7-27b594fdfd85')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a69c880d-9640-4ea5-97e7-27b594fdfd85 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a69c880d-9640-4ea5-97e7-27b594fdfd85');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            title_raw  \\\n",
       "2                   Clustering and Arnoux-Rauzy words   \n",
       "6   Endemic Oscillations for SARS-CoV-2 Omicron --...   \n",
       "12           A sub-Riemannian maximum modulus theorem   \n",
       "19  One-parameter discrete-time Calogero-Moser system   \n",
       "24  Boundary rigidity, and non-rigidity, of projec...   \n",
       "28  On the reduced space of multiplicative multive...   \n",
       "31  Sharp bounds on the height of K-semistable tor...   \n",
       "44  Enumerative geometry via the moduli space of s...   \n",
       "\n",
       "                                         abstract_raw  \\\n",
       "2   We characterize the clustering of a word under...   \n",
       "6   The SIRS model with constant vaccination and i...   \n",
       "12  In this note we prove a sub-Riemannian maximum...   \n",
       "19  We present a new type of integrable one-dimens...   \n",
       "24  We investigate the property of boundary rigidi...   \n",
       "28  A strict Lie $2$-algebra $\\Gamma(\\wedge^\\bulle...   \n",
       "31  Inspired by Fujita's algebro-geometric result ...   \n",
       "44  In this paper we relate volumes of moduli spac...   \n",
       "\n",
       "                                    fine_topic_labels  \n",
       "2   22 | grassmannians | grassmann | grassmannian ...  \n",
       "6   2 | lie | lie algebras | algebras | lie groups...  \n",
       "12  -1 | theory | quantum | field | algebra | spac...  \n",
       "19  2 | lie | lie algebras | algebras | lie groups...  \n",
       "24  14 | symplectic | poisson | manifolds | manifo...  \n",
       "28  6 | branes | brane | calabi yau | yau | calabi...  \n",
       "31  10 | string | boundary | entanglement | bulk |...  \n",
       "44  10 | string | boundary | entanglement | bulk |...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Evaluate the labels by eye-test\n",
    "eye_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IT8EA_jpmmg"
   },
   "source": [
    "The outlier stats are obviously fucked up, fix tomorrow morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRyXFPk6pvp4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9pHR9Pi4KbSh"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
