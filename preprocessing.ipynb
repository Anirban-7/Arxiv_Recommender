{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3595951b",
   "metadata": {},
   "source": [
    "### Preprocessing the collected abstracts to remove uncommon words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c2cd778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from string import punctuation\n",
    "from data_utils import clean_data, clean_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1359f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "## May need to install pyarrow or fastparquet to process this\n",
    "## df = pd.read_parquet(\"./data/recent_50k.parquet\")\n",
    "## df = pd.read_parquet(\"./data/eng_175k.parquet\")\n",
    "## df = pd.read_parquet(\"./data/eng_50k.parquet\")\n",
    "df = pd.read_parquet(\"./data/filter_20k.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3c8b49b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>strip_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182244</th>\n",
       "      <td>1412.3275</td>\n",
       "      <td>Limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>We study the maximum number of limit cycles ...</td>\n",
       "      <td>2014-12-11</td>\n",
       "      <td>[['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]</td>\n",
       "      <td>[DS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196425</th>\n",
       "      <td>0809.3510</td>\n",
       "      <td>Shrinking Point Bifurcations of Resonance Tong...</td>\n",
       "      <td>Resonance tongues are modelocking regions of...</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>[['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....</td>\n",
       "      <td>[DS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479424</th>\n",
       "      <td>2201.04222</td>\n",
       "      <td>Classification of Codimension1 Singular Bifurc...</td>\n",
       "      <td>The study of bifurcations of differentialalg...</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>[['Ovsyannikov', 'Ivan', ''], ['Ruan', 'Haibo'...</td>\n",
       "      <td>[DS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176385</th>\n",
       "      <td>1408.5812</td>\n",
       "      <td>Partial sums of excursions along random geodes...</td>\n",
       "      <td>For a nonuniform lattice in SL(2,R), we cons...</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>[['Gadre', 'Vaibhav', '']]</td>\n",
       "      <td>[GT, DS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291058</th>\n",
       "      <td>1707.03102</td>\n",
       "      <td>Uniform dimension results for a family of Mark...</td>\n",
       "      <td>In this paper we prove uniform Hausdorff and...</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>[['Sun', 'Xiaobin', ''], ['Xiao', 'Yimin', '']...</td>\n",
       "      <td>[PR]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                              title  \\\n",
       "182244   1412.3275  Limit cycles bifurcating from a degenerate center   \n",
       "196425   0809.3510  Shrinking Point Bifurcations of Resonance Tong...   \n",
       "479424  2201.04222  Classification of Codimension1 Singular Bifurc...   \n",
       "176385   1408.5812  Partial sums of excursions along random geodes...   \n",
       "291058  1707.03102  Uniform dimension results for a family of Mark...   \n",
       "\n",
       "                                                 abstract update_date  \\\n",
       "182244    We study the maximum number of limit cycles ...  2014-12-11   \n",
       "196425    Resonance tongues are modelocking regions of...  2015-05-13   \n",
       "479424    The study of bifurcations of differentialalg...  2022-01-13   \n",
       "176385    For a nonuniform lattice in SL(2,R), we cons...  2014-10-09   \n",
       "291058    In this paper we prove uniform Hausdorff and...  2017-10-03   \n",
       "\n",
       "                                           authors_parsed strip_cat  \n",
       "182244      [['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]      [DS]  \n",
       "196425  [['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....      [DS]  \n",
       "479424  [['Ovsyannikov', 'Ivan', ''], ['Ruan', 'Haibo'...      [DS]  \n",
       "176385                         [['Gadre', 'Vaibhav', '']]  [GT, DS]  \n",
       "291058  [['Sun', 'Xiaobin', ''], ['Xiao', 'Yimin', '']...      [PR]  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a04a083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean the title and abstracts in the database\n",
    "## Adding three new columns to the database\n",
    "df['clean_title'] = df['title'].apply(clean_data)\n",
    "df['clean_abstract'] = df['abstract'].apply(clean_data)\n",
    "df['clean_authors'] = df['authors_parsed'].apply(clean_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e3f1b562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_abstract</th>\n",
       "      <th>clean_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182244</th>\n",
       "      <td>1412.3275</td>\n",
       "      <td>Limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>We study the maximum number of limit cycles ...</td>\n",
       "      <td>2014-12-11</td>\n",
       "      <td>[['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>we study the maximum number of limit cycles th...</td>\n",
       "      <td>[['llibre', 'j', ''], ['pantazi', 'c', '']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196425</th>\n",
       "      <td>0809.3510</td>\n",
       "      <td>Shrinking Point Bifurcations of Resonance Tong...</td>\n",
       "      <td>Resonance tongues are modelocking regions of...</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>[['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>shrinking point bifurcations of resonance tong...</td>\n",
       "      <td>resonance tongues are modelocking regions of p...</td>\n",
       "      <td>[['simpson', 'd j w', ''], ['meiss', 'j d', '']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479424</th>\n",
       "      <td>2201.04222</td>\n",
       "      <td>Classification of Codimension1 Singular Bifurc...</td>\n",
       "      <td>The study of bifurcations of differentialalg...</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>[['Ovsyannikov', 'Ivan', ''], ['Ruan', 'Haibo'...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>classification of codimension singular bifurca...</td>\n",
       "      <td>the study of bifurcations of differentialalgeb...</td>\n",
       "      <td>[['ovsyannikov', 'ivan', ''], ['ruan', 'haibo'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176385</th>\n",
       "      <td>1408.5812</td>\n",
       "      <td>Partial sums of excursions along random geodes...</td>\n",
       "      <td>For a nonuniform lattice in SL(2,R), we cons...</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>[['Gadre', 'Vaibhav', '']]</td>\n",
       "      <td>[GT, DS]</td>\n",
       "      <td>partial sums of excursions along random geodes...</td>\n",
       "      <td>for a nonuniform lattice in slr we consider ex...</td>\n",
       "      <td>[['gadre', 'vaibhav', '']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291058</th>\n",
       "      <td>1707.03102</td>\n",
       "      <td>Uniform dimension results for a family of Mark...</td>\n",
       "      <td>In this paper we prove uniform Hausdorff and...</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>[['Sun', 'Xiaobin', ''], ['Xiao', 'Yimin', '']...</td>\n",
       "      <td>[PR]</td>\n",
       "      <td>uniform dimension results for a family of mark...</td>\n",
       "      <td>in this paper we prove uniform hausdorff and p...</td>\n",
       "      <td>[['sun', 'xiaobin', ''], ['xiao', 'yimin', '']...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                              title  \\\n",
       "182244   1412.3275  Limit cycles bifurcating from a degenerate center   \n",
       "196425   0809.3510  Shrinking Point Bifurcations of Resonance Tong...   \n",
       "479424  2201.04222  Classification of Codimension1 Singular Bifurc...   \n",
       "176385   1408.5812  Partial sums of excursions along random geodes...   \n",
       "291058  1707.03102  Uniform dimension results for a family of Mark...   \n",
       "\n",
       "                                                 abstract update_date  \\\n",
       "182244    We study the maximum number of limit cycles ...  2014-12-11   \n",
       "196425    Resonance tongues are modelocking regions of...  2015-05-13   \n",
       "479424    The study of bifurcations of differentialalg...  2022-01-13   \n",
       "176385    For a nonuniform lattice in SL(2,R), we cons...  2014-10-09   \n",
       "291058    In this paper we prove uniform Hausdorff and...  2017-10-03   \n",
       "\n",
       "                                           authors_parsed strip_cat  \\\n",
       "182244      [['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]      [DS]   \n",
       "196425  [['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....      [DS]   \n",
       "479424  [['Ovsyannikov', 'Ivan', ''], ['Ruan', 'Haibo'...      [DS]   \n",
       "176385                         [['Gadre', 'Vaibhav', '']]  [GT, DS]   \n",
       "291058  [['Sun', 'Xiaobin', ''], ['Xiao', 'Yimin', '']...      [PR]   \n",
       "\n",
       "                                              clean_title  \\\n",
       "182244  limit cycles bifurcating from a degenerate center   \n",
       "196425  shrinking point bifurcations of resonance tong...   \n",
       "479424  classification of codimension singular bifurca...   \n",
       "176385  partial sums of excursions along random geodes...   \n",
       "291058  uniform dimension results for a family of mark...   \n",
       "\n",
       "                                           clean_abstract  \\\n",
       "182244  we study the maximum number of limit cycles th...   \n",
       "196425  resonance tongues are modelocking regions of p...   \n",
       "479424  the study of bifurcations of differentialalgeb...   \n",
       "176385  for a nonuniform lattice in slr we consider ex...   \n",
       "291058  in this paper we prove uniform hausdorff and p...   \n",
       "\n",
       "                                            clean_authors  \n",
       "182244        [['llibre', 'j', ''], ['pantazi', 'c', '']]  \n",
       "196425   [['simpson', 'd j w', ''], ['meiss', 'j d', '']]  \n",
       "479424  [['ovsyannikov', 'ivan', ''], ['ruan', 'haibo'...  \n",
       "176385                         [['gadre', 'vaibhav', '']]  \n",
       "291058  [['sun', 'xiaobin', ''], ['xiao', 'yimin', '']...  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "327c1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstract_tokenized'] = df['clean_abstract'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ca98d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get rid of the occasional empty string.\n",
    "def clear_empty(clean_string):\n",
    "    return [word for word in clean_string if word != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ab38107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstract_tokenized'] = df['abstract_tokenized'].apply(clear_empty) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f81146",
   "metadata": {},
   "source": [
    "Now we create a corpus of all the words (non-unique) that appear in the abstracts and then find the frequency distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "259333a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988337\n"
     ]
    }
   ],
   "source": [
    "indices = df.index.values\n",
    "\n",
    "# Corpus will be a list of lists\n",
    "corpus = []\n",
    "for i  in indices:\n",
    "    corpus.append(df['abstract_tokenized'][i])\n",
    "\n",
    "# Convert a list of lists to a list because FreqDist takes in a\n",
    "# list of strings\n",
    "flat_corpus = []\n",
    "for sublist in corpus:\n",
    "    for item in sublist:\n",
    "        flat_corpus.append(item)\n",
    "        \n",
    "print(len(flat_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e2617a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 44183 words in the frequency distribution.\n"
     ]
    }
   ],
   "source": [
    "# Create a frequency distribution from the flattened corpus\n",
    "freq = FreqDist(flat_corpus)\n",
    "print(\"There are\", len(freq), \"words in the frequency distribution.\")\n",
    "## For the eng_50k dataset there were 66993 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f2776bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22091</th>\n",
       "      <td>evidently</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30532</th>\n",
       "      <td>amplitudesquared</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30533</th>\n",
       "      <td>gsignature</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30534</th>\n",
       "      <td>fullerene</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16061</th>\n",
       "      <td>thermostats</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16060</th>\n",
       "      <td>generelized</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30536</th>\n",
       "      <td>uqslmodules</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30538</th>\n",
       "      <td>teepee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30539</th>\n",
       "      <td>chameleon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16065</th>\n",
       "      <td>epde</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30540</th>\n",
       "      <td>accelerationenlarged</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30543</th>\n",
       "      <td>silnikov</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16052</th>\n",
       "      <td>temperatureaccelerated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30545</th>\n",
       "      <td>pentagrid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16050</th>\n",
       "      <td>dilatons</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30546</th>\n",
       "      <td>macroscopical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16048</th>\n",
       "      <td>hyperinstantons</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30547</th>\n",
       "      <td>normpreservation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30548</th>\n",
       "      <td>thetadeformations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30542</th>\n",
       "      <td>lw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30531</th>\n",
       "      <td>representaions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30529</th>\n",
       "      <td>empiricalmagnetization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30528</th>\n",
       "      <td>densityprofile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16089</th>\n",
       "      <td>collectivismwas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16088</th>\n",
       "      <td>attitudesegoism</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30518</th>\n",
       "      <td>pnnablaphi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16086</th>\n",
       "      <td>quo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16084</th>\n",
       "      <td>regrading</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30520</th>\n",
       "      <td>modesum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16082</th>\n",
       "      <td>ptinvariant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16081</th>\n",
       "      <td>bessis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16080</th>\n",
       "      <td>automatize</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16078</th>\n",
       "      <td>selfeducation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16077</th>\n",
       "      <td>exams</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30522</th>\n",
       "      <td>antiparticle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30524</th>\n",
       "      <td>thresholdtype</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30525</th>\n",
       "      <td>pogan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30526</th>\n",
       "      <td>timeevolutionary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30527</th>\n",
       "      <td>khomological</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16071</th>\n",
       "      <td>textitalias</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16070</th>\n",
       "      <td>jonesrosso</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16069</th>\n",
       "      <td>heines</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30549</th>\n",
       "      <td>simplexes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16090</th>\n",
       "      <td>collectivists</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30550</th>\n",
       "      <td>grandparent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>areaconstrained</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16016</th>\n",
       "      <td>balescu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30563</th>\n",
       "      <td>updown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30565</th>\n",
       "      <td>radialimproved</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16013</th>\n",
       "      <td>ninftyso</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Word  Frequency\n",
       "22091               evidently          1\n",
       "30532        amplitudesquared          1\n",
       "30533              gsignature          1\n",
       "30534               fullerene          1\n",
       "16061             thermostats          1\n",
       "16060             generelized          1\n",
       "30536             uqslmodules          1\n",
       "30538                  teepee          1\n",
       "30539               chameleon          1\n",
       "16065                    epde          1\n",
       "30540    accelerationenlarged          1\n",
       "30543                silnikov          1\n",
       "16052  temperatureaccelerated          1\n",
       "30545               pentagrid          1\n",
       "16050                dilatons          1\n",
       "30546           macroscopical          1\n",
       "16048         hyperinstantons          1\n",
       "30547        normpreservation          1\n",
       "30548       thetadeformations          1\n",
       "30542                      lw          1\n",
       "30531          representaions          1\n",
       "30529  empiricalmagnetization          1\n",
       "30528          densityprofile          1\n",
       "16089         collectivismwas          1\n",
       "16088         attitudesegoism          1\n",
       "30518              pnnablaphi          1\n",
       "16086                     quo          1\n",
       "16084               regrading          1\n",
       "30520                 modesum          1\n",
       "16082             ptinvariant          1\n",
       "16081                  bessis          1\n",
       "16080              automatize          1\n",
       "16078           selfeducation          1\n",
       "16077                   exams          1\n",
       "30522            antiparticle          1\n",
       "30524           thresholdtype          1\n",
       "30525                   pogan          1\n",
       "30526        timeevolutionary          1\n",
       "30527            khomological          1\n",
       "16071             textitalias          1\n",
       "16070              jonesrosso          1\n",
       "16069                  heines          1\n",
       "30549               simplexes          1\n",
       "16090           collectivists          1\n",
       "30550             grandparent          1\n",
       "16042         areaconstrained          1\n",
       "16016                 balescu          1\n",
       "30563                  updown          1\n",
       "30565          radialimproved          1\n",
       "16013                ninftyso          1"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fdist = pd.DataFrame(list(freq.items()), columns = [\"Word\",\"Frequency\"])\n",
    "df_fdist = df_fdist.sort_values(by=\"Frequency\", ascending=True)\n",
    "df_fdist.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cd29d8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21707 words that appear only once in the abstracts.\n"
     ]
    }
   ],
   "source": [
    "## Create a list of the words that appear only once\n",
    "unique_words = list(df_fdist[df_fdist['Frequency'] == 1]['Word'])\n",
    "print(\"There are\", len(unique_words), \"words that appear only once in the abstracts.\")\n",
    "## Fort he eng_50k dataset there were 28097 words that appear only once in the abstracts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff4978a",
   "metadata": {},
   "source": [
    "We also want to remove common stopwords from the abstracts. We will append these to the unique words, so then wew only need to iterate through the dataframe once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "26b8c298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      " !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~’‘\n",
      "\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'youre', 'youve', 'youll', 'youd', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'shes', 'her', 'hers', 'herself', 'it', 'its', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'thatll', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'dont', 'should', 'shouldve', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'arent', 'couldn', 'couldnt', 'didn', 'didnt', 'doesn', 'doesnt', 'hadn', 'hadnt', 'hasn', 'hasnt', 'haven', 'havent', 'isn', 'isnt', 'ma', 'mightn', 'mightnt', 'mustn', 'mustnt', 'needn', 'neednt', 'shan', 'shant', 'shouldn', 'shouldnt', 'wasn', 'wasnt', 'weren', 'werent', 'won', 'wont', 'wouldn', 'wouldnt']\n"
     ]
    }
   ],
   "source": [
    "eng_stopwords = stopwords.words('english')\n",
    "print(stopwords.words('english'))\n",
    "\n",
    "## Remove punctutation from stopwords because we've already r\n",
    "## removed it from the abstracts\n",
    "## punctuation is imported from the string class\n",
    "new_punct = punctuation + \"’\" + \"‘\"\n",
    "print(\"\\n\", new_punct)\n",
    "print()\n",
    "\n",
    "new_stop = []\n",
    "for word in eng_stopwords:\n",
    "    new_word = \"\"\n",
    "    for char in word:\n",
    "        if char not in new_punct:\n",
    "            new_word = new_word + char\n",
    "        # print(new_word)\n",
    "    new_stop.append(new_word)\n",
    "    \n",
    "print(new_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "4d396321",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words = new_stop + unique_words\n",
    "\n",
    "## Remove infrequent words and stop words from the tokenized abstracts\n",
    "def remove_stop_unique(tokens):\n",
    "    return [token for token in tokens if token not in remove_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "68d6863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 9s, sys: 2.4 s, total: 8min 12s\n",
      "Wall time: 8min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['abstract_reduced_tokens'] = df['abstract_tokenized'].apply(remove_stop_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9b8d8a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>strip_cat</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_abstract</th>\n",
       "      <th>clean_authors</th>\n",
       "      <th>abstract_tokenized</th>\n",
       "      <th>abstract_reduced_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182244</th>\n",
       "      <td>1412.3275</td>\n",
       "      <td>Limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>We study the maximum number of limit cycles ...</td>\n",
       "      <td>2014-12-11</td>\n",
       "      <td>[['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>limit cycles bifurcating from a degenerate center</td>\n",
       "      <td>we study the maximum number of limit cycles th...</td>\n",
       "      <td>[['llibre', 'j', ''], ['pantazi', 'c', '']]</td>\n",
       "      <td>[we, study, the, maximum, number, of, limit, c...</td>\n",
       "      <td>[study, maximum, number, limit, cycles, bifurc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196425</th>\n",
       "      <td>0809.3510</td>\n",
       "      <td>Shrinking Point Bifurcations of Resonance Tong...</td>\n",
       "      <td>Resonance tongues are modelocking regions of...</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>[['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>shrinking point bifurcations of resonance tong...</td>\n",
       "      <td>resonance tongues are modelocking regions of p...</td>\n",
       "      <td>[['simpson', 'd j w', ''], ['meiss', 'j d', '']]</td>\n",
       "      <td>[resonance, tongues, are, modelocking, regions...</td>\n",
       "      <td>[resonance, tongues, modelocking, regions, par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479424</th>\n",
       "      <td>2201.04222</td>\n",
       "      <td>Classification of Codimension1 Singular Bifurc...</td>\n",
       "      <td>The study of bifurcations of differentialalg...</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>[['Ovsyannikov', 'Ivan', ''], ['Ruan', 'Haibo'...</td>\n",
       "      <td>[DS]</td>\n",
       "      <td>classification of codimension singular bifurca...</td>\n",
       "      <td>the study of bifurcations of differentialalgeb...</td>\n",
       "      <td>[['ovsyannikov', 'ivan', ''], ['ruan', 'haibo'...</td>\n",
       "      <td>[the, study, of, bifurcations, of, differentia...</td>\n",
       "      <td>[study, bifurcations, differentialalgebraic, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176385</th>\n",
       "      <td>1408.5812</td>\n",
       "      <td>Partial sums of excursions along random geodes...</td>\n",
       "      <td>For a nonuniform lattice in SL(2,R), we cons...</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>[['Gadre', 'Vaibhav', '']]</td>\n",
       "      <td>[GT, DS]</td>\n",
       "      <td>partial sums of excursions along random geodes...</td>\n",
       "      <td>for a nonuniform lattice in slr we consider ex...</td>\n",
       "      <td>[['gadre', 'vaibhav', '']]</td>\n",
       "      <td>[for, a, nonuniform, lattice, in, slr, we, con...</td>\n",
       "      <td>[nonuniform, lattice, slr, consider, excursion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291058</th>\n",
       "      <td>1707.03102</td>\n",
       "      <td>Uniform dimension results for a family of Mark...</td>\n",
       "      <td>In this paper we prove uniform Hausdorff and...</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>[['Sun', 'Xiaobin', ''], ['Xiao', 'Yimin', '']...</td>\n",
       "      <td>[PR]</td>\n",
       "      <td>uniform dimension results for a family of mark...</td>\n",
       "      <td>in this paper we prove uniform hausdorff and p...</td>\n",
       "      <td>[['sun', 'xiaobin', ''], ['xiao', 'yimin', '']...</td>\n",
       "      <td>[in, this, paper, we, prove, uniform, hausdorf...</td>\n",
       "      <td>[paper, prove, uniform, hausdorff, packing, di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                              title  \\\n",
       "182244   1412.3275  Limit cycles bifurcating from a degenerate center   \n",
       "196425   0809.3510  Shrinking Point Bifurcations of Resonance Tong...   \n",
       "479424  2201.04222  Classification of Codimension1 Singular Bifurc...   \n",
       "176385   1408.5812  Partial sums of excursions along random geodes...   \n",
       "291058  1707.03102  Uniform dimension results for a family of Mark...   \n",
       "\n",
       "                                                 abstract update_date  \\\n",
       "182244    We study the maximum number of limit cycles ...  2014-12-11   \n",
       "196425    Resonance tongues are modelocking regions of...  2015-05-13   \n",
       "479424    The study of bifurcations of differentialalg...  2022-01-13   \n",
       "176385    For a nonuniform lattice in SL(2,R), we cons...  2014-10-09   \n",
       "291058    In this paper we prove uniform Hausdorff and...  2017-10-03   \n",
       "\n",
       "                                           authors_parsed strip_cat  \\\n",
       "182244      [['Llibre', 'J.', ''], ['Pantazi', 'C.', '']]      [DS]   \n",
       "196425  [['Simpson', 'D. J. W.', ''], ['Meiss', 'J. D....      [DS]   \n",
       "479424  [['Ovsyannikov', 'Ivan', ''], ['Ruan', 'Haibo'...      [DS]   \n",
       "176385                         [['Gadre', 'Vaibhav', '']]  [GT, DS]   \n",
       "291058  [['Sun', 'Xiaobin', ''], ['Xiao', 'Yimin', '']...      [PR]   \n",
       "\n",
       "                                              clean_title  \\\n",
       "182244  limit cycles bifurcating from a degenerate center   \n",
       "196425  shrinking point bifurcations of resonance tong...   \n",
       "479424  classification of codimension singular bifurca...   \n",
       "176385  partial sums of excursions along random geodes...   \n",
       "291058  uniform dimension results for a family of mark...   \n",
       "\n",
       "                                           clean_abstract  \\\n",
       "182244  we study the maximum number of limit cycles th...   \n",
       "196425  resonance tongues are modelocking regions of p...   \n",
       "479424  the study of bifurcations of differentialalgeb...   \n",
       "176385  for a nonuniform lattice in slr we consider ex...   \n",
       "291058  in this paper we prove uniform hausdorff and p...   \n",
       "\n",
       "                                            clean_authors  \\\n",
       "182244        [['llibre', 'j', ''], ['pantazi', 'c', '']]   \n",
       "196425   [['simpson', 'd j w', ''], ['meiss', 'j d', '']]   \n",
       "479424  [['ovsyannikov', 'ivan', ''], ['ruan', 'haibo'...   \n",
       "176385                         [['gadre', 'vaibhav', '']]   \n",
       "291058  [['sun', 'xiaobin', ''], ['xiao', 'yimin', '']...   \n",
       "\n",
       "                                       abstract_tokenized  \\\n",
       "182244  [we, study, the, maximum, number, of, limit, c...   \n",
       "196425  [resonance, tongues, are, modelocking, regions...   \n",
       "479424  [the, study, of, bifurcations, of, differentia...   \n",
       "176385  [for, a, nonuniform, lattice, in, slr, we, con...   \n",
       "291058  [in, this, paper, we, prove, uniform, hausdorf...   \n",
       "\n",
       "                                  abstract_reduced_tokens  \n",
       "182244  [study, maximum, number, limit, cycles, bifurc...  \n",
       "196425  [resonance, tongues, modelocking, regions, par...  \n",
       "479424  [study, bifurcations, differentialalgebraic, e...  \n",
       "176385  [nonuniform, lattice, slr, consider, excursion...  \n",
       "291058  [paper, prove, uniform, hausdorff, packing, di...  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "904be5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117534\n",
      "870803\n"
     ]
    }
   ],
   "source": [
    "# Corpus will be a list of lists\n",
    "corpus_2 = []\n",
    "for i  in indices:\n",
    "    corpus_2.append(df['abstract_reduced_tokens'][i])\n",
    "\n",
    "# Convert a list of lists to a list because FreqDist takes in a\n",
    "# list of strings\n",
    "flat_corpus_2 = []\n",
    "for sublist in corpus_2:\n",
    "    for item in sublist:\n",
    "        flat_corpus_2.append(item)\n",
    "        \n",
    "print(len(flat_corpus_2))\n",
    "print(len(flat_corpus) - len(flat_corpus_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1336899e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22344 words in the frequency distribution.\n"
     ]
    }
   ],
   "source": [
    "## Let's look at the frequency distribution again.\n",
    "freq_2 = FreqDist(flat_corpus_2)\n",
    "print(\"There are\", len(freq_2), \"words in the frequency distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "75e1a610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('show', 6191),\n",
       " ('prove', 5995),\n",
       " ('paper', 5811),\n",
       " ('also', 5518),\n",
       " ('equation', 5469),\n",
       " ('space', 5416),\n",
       " ('solutions', 5301),\n",
       " ('results', 5280),\n",
       " ('study', 5101),\n",
       " ('equations', 5029),\n",
       " ('model', 4837),\n",
       " ('problem', 4608),\n",
       " ('case', 4445),\n",
       " ('theory', 4332),\n",
       " ('system', 4303),\n",
       " ('two', 4278),\n",
       " ('random', 4063),\n",
       " ('one', 3931),\n",
       " ('time', 3893),\n",
       " ('function', 3652),\n",
       " ('result', 3617),\n",
       " ('systems', 3478),\n",
       " ('boundary', 3443),\n",
       " ('solution', 3435),\n",
       " ('consider', 3338),\n",
       " ('new', 3332),\n",
       " ('general', 3126),\n",
       " ('quantum', 3119),\n",
       " ('functions', 3099),\n",
       " ('existence', 3039),\n",
       " ('using', 2981),\n",
       " ('conditions', 2959),\n",
       " ('given', 2941),\n",
       " ('class', 2872),\n",
       " ('field', 2857),\n",
       " ('method', 2854),\n",
       " ('first', 2853),\n",
       " ('set', 2794),\n",
       " ('particular', 2721),\n",
       " ('limit', 2648),\n",
       " ('finite', 2644),\n",
       " ('order', 2623),\n",
       " ('give', 2572),\n",
       " ('process', 2510),\n",
       " ('terms', 2481),\n",
       " ('operator', 2463),\n",
       " ('number', 2458),\n",
       " ('type', 2457),\n",
       " ('group', 2432),\n",
       " ('theorem', 2334)]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## These are the most common words, perhaps we would want to remove some of them?\n",
    "freq_2.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "fd3e28ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the dataframe to a parquet file\n",
    "df.to_parquet('./filter_20k_tokenized.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8bec9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the parquet file\n",
    "# df_new = pd.read_parquet('./eng_50k_tokenized.gzip')\n",
    "#df_new = pd.read_parquet('./filter_20k_tokenized.parquet')\n",
    "#df_new.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
